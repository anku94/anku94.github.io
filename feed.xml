<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://anku94.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://anku94.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-07-10T01:52:07+00:00</updated><id>https://anku94.github.io/feed.xml</id><title type="html">Ankush Jain</title><subtitle>Personal website and blog of Ankush Jain, PhD Student at CMU PDL. Topics include systems, storage, networks, HPC etc. </subtitle><entry><title type="html">Inscrutable Coredump v. Unmoveable Grad Student</title><link href="https://anku94.github.io/blog/2024/inscrutable-core-dump/" rel="alternate" type="text/html" title="Inscrutable Coredump v. Unmoveable Grad Student"/><published>2024-07-09T19:24:13+00:00</published><updated>2024-07-09T19:24:13+00:00</updated><id>https://anku94.github.io/blog/2024/inscrutable-core-dump</id><content type="html" xml:base="https://anku94.github.io/blog/2024/inscrutable-core-dump/"><![CDATA[<p>Situation: we have a core dump that is shy to reveal its inner workings. The goal is to extract some more information from this core dump, using fancier analyses. The core dump is 1.2GB in size, so I know that there is some insight in there, it is just buried.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) bt</span><span class="w">
</span>#0<span class="w">  </span><span class="mh">0x00007fbaa4653c30</span><span class="w"> </span>in<span class="w"> </span>??<span class="w"> </span><span class="p">()</span><span class="w">
</span>#1<span class="w">  </span><span class="mh">0x0000000000000000</span><span class="w"> </span>in<span class="w"> </span>??<span class="w"> </span><span class="p">()</span><span class="w">
</span></code></pre></div></div> <p>Since we have an intact <code class="language-plaintext highlighter-rouge">$pc</code> (which refers to <code class="language-plaintext highlighter-rouge">%rip</code>), we can figure out the instructions it was executing.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) disassemble $pc-20,$pc+20</span><span class="w">
</span>Dump<span class="w"> </span>of<span class="w"> </span>assembler<span class="w"> </span>code<span class="w"> </span>from<span class="w"> </span><span class="mh">0x7fbaa4653c1c</span><span class="w"> </span>to<span class="w"> </span><span class="mh">0x7fbaa4653c44</span>:<span class="w">
   </span><span class="mh">0x00007fbaa4653c1c</span>:<span class="w">  </span>add<span class="w">    </span><span class="nv">%al</span><span class="p">,(</span><span class="nv">%rax</span><span class="p">)</span><span class="w">
   </span><span class="mh">0x00007fbaa4653c1e</span>:<span class="w">  </span>jmp<span class="w">    </span><span class="mh">0x7fbaa4653a51</span><span class="w">
   </span><span class="mh">0x00007fbaa4653c23</span>:<span class="w">  </span>nopl<span class="w">   </span><span class="mh">0x0</span><span class="p">(</span><span class="nv">%rax</span><span class="p">,</span><span class="nv">%rax</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="w">
   </span><span class="mh">0x00007fbaa4653c28</span>:<span class="w">  </span>mov<span class="w">    </span><span class="mh">0x98</span><span class="p">(</span><span class="nv">%r12</span><span class="p">),</span><span class="nv">%rax</span><span class="w">
</span>=&gt;<span class="w"> </span><span class="mh">0x00007fbaa4653c30</span>:<span class="w">  </span>cmpb<span class="w">   </span>$0x48,(%rax)<span class="w">
   </span><span class="mh">0x00007fbaa4653c33</span>:<span class="w">  </span>jne<span class="w">    </span><span class="mh">0x7fbaa4653b90</span><span class="w">
   </span><span class="mh">0x00007fbaa4653c39</span>:<span class="w">  </span>movabs<span class="w"> </span>$0x50f0000000fc0c7,%rdx<span class="w">
   </span><span class="mh">0x00007fbaa4653c43</span>:<span class="w">  </span>cmp<span class="w">    </span><span class="nv">%rdx</span><span class="p">,</span><span class="mh">0x1</span><span class="p">(</span><span class="nv">%rax</span><span class="p">)</span><span class="w">
</span>End<span class="w"> </span>of<span class="w"> </span>assembler<span class="w"> </span>dump.<span class="w">
</span></code></pre></div></div> <p>Let us inspect the registers.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) info reg</span><span class="w">
</span>rax<span class="w">            </span><span class="mh">0x323338342034342e</span><span class="w">  </span><span class="mi">3617296722238387246</span><span class="w">
</span>rbx<span class="w">            </span><span class="mh">0x7fff678ebb50</span><span class="w">      </span><span class="mi">140734930795344</span><span class="w">
</span>rcx<span class="w">            </span><span class="mh">0x7fba82086120</span><span class="w">      </span><span class="mi">140439022231840</span><span class="w">
</span>rdx<span class="w">            </span><span class="mh">0x1</span><span class="w">                 </span><span class="mi">1</span><span class="w">
</span>rsi<span class="w">            </span><span class="mh">0x1</span><span class="w">                 </span><span class="mi">1</span><span class="w">
</span></code></pre></div></div> <p>Okay so our <code class="language-plaintext highlighter-rouge">%rax</code> was clearly a gibberish address, no wonder dereferencing it failed. Now the question is what source file/line was mapped to <code class="language-plaintext highlighter-rouge">$pc</code>. ChatGPT says that the following can work:</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) list *$pc</span><span class="w">
</span>&lt;no<span class="w"> </span>output&gt;<span class="w">
</span><span class="gp">(gdb) info symbol $pc</span><span class="w">
</span>No<span class="w"> </span>symbol<span class="w"> </span>matches<span class="w"> </span>$pc.<span class="w">
</span></code></pre></div></div> <p>ChatGPT also says that we can also dereference addresses using these, but first we need to know what library is laid out in our memory, and at what offset. Noting these down for later.</p> <div class="language-session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$ addr2line -e /path/to/your/executable 0xADDRESS</span><span class="w">
</span><span class="gp">$ objdump -d -S /path/to/your/executable</span><span class="w">
</span></code></pre></div></div> <p>Some more useful information, saving for later.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) info frame 0</span><span class="w">
</span>Stack<span class="w"> </span>frame<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebaf8</span>:<span class="w">
 </span>rip<span class="w"> </span>=<span class="w"> </span><span class="mh">0x7fbaa4653c30</span>;<span class="w"> </span>saved<span class="w"> </span>rip<span class="w"> </span>=<span class="w"> </span><span class="mh">0x0</span><span class="w">
 </span>called<span class="w"> </span>by<span class="w"> </span>frame<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebb00</span><span class="w">
 </span>Arglist<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebae8</span><span class="p">,</span><span class="w"> </span>args:<span class="w">
 </span>Locals<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebae8</span><span class="p">,</span><span class="w"> </span>Previous<span class="w"> </span>frame's<span class="w"> </span>sp<span class="w"> </span>is<span class="w"> </span><span class="mh">0x7fff678ebaf8</span><span class="w">
 </span>Saved<span class="w"> </span>registers:<span class="w">
  </span>rip<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebaf0</span><span class="w">
</span><span class="gp">(gdb) info frame 1</span><span class="w">
</span>Stack<span class="w"> </span>frame<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebb00</span>:<span class="w">
 </span>rip<span class="w"> </span>=<span class="w"> </span><span class="mh">0x0</span>;<span class="w"> </span>saved<span class="w"> </span>rip<span class="w"> </span>=<span class="w"> </span><span class="mh">0x0</span><span class="w">
 </span>caller<span class="w"> </span>of<span class="w"> </span>frame<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebaf8</span><span class="w">
 </span>Arglist<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebaf0</span><span class="p">,</span><span class="w"> </span>args:<span class="w">
 </span>Locals<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebaf0</span><span class="p">,</span><span class="w"> </span>Previous<span class="w"> </span>frame's<span class="w"> </span>sp<span class="w"> </span>is<span class="w"> </span><span class="mh">0x7fff678ebb00</span><span class="w">
 </span>Saved<span class="w"> </span>registers:<span class="w">
  </span>rip<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebaf8</span><span class="w">
</span><span class="gp">(gdb) info frame 2</span><span class="w">
</span>No<span class="w"> </span>frame<span class="w"> </span>at<span class="w"> </span>level<span class="w"> </span><span class="mi">2</span>.<span class="w">
</span></code></pre></div></div> <p>Let’s look at shared memory mappings now.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) info shared</span><span class="w">
</span>No<span class="w"> </span>shared<span class="w"> </span>libraries<span class="w"> </span>loaded<span class="w"> </span>at<span class="w"> </span>this<span class="w"> </span>time.<span class="w">
</span><span class="gp">(gdb) info proc mappings</span><span class="w">
</span>Mapped<span class="w"> </span>address<span class="w"> </span>spaces:<span class="w">

          </span>Start<span class="w"> </span>Addr<span class="w">           </span>End<span class="w"> </span>Addr<span class="w">       </span>Size<span class="w">     </span>Offset<span class="w"> </span>objfile<span class="w">
      </span><span class="mh">0x5585a6034000</span><span class="w">     </span><span class="mh">0x5585a604b000</span><span class="w">    </span><span class="mh">0x17000</span><span class="w">        </span><span class="mh">0x0</span><span class="w"> </span>/some/bin<span class="w">
      </span><span class="mh">0x5585a604b000</span><span class="w">     </span><span class="mh">0x5585a64ef000</span><span class="w">   </span><span class="mh">0x4a4000</span><span class="w">    </span><span class="mh">0x17000</span><span class="w"> </span>/some/bin<span class="w">
      </span><span class="mh">0x5585a64ef000</span><span class="w">     </span><span class="mh">0x5585a6582000</span><span class="w">    </span><span class="mh">0x93000</span><span class="w">   </span><span class="mh">0x4bb000</span><span class="w"> </span>/some/bin<span class="w">
      </span><span class="mh">0x7fba3ad28000</span><span class="w">     </span><span class="mh">0x7fba3c000000</span><span class="w">  </span><span class="mh">0x12d8000</span><span class="w">        </span><span class="mh">0x0</span><span class="w"> </span>/dev/shm/...<span class="w">
      </span><span class="mh">0x7fba40d29000</span><span class="w">     </span><span class="mh">0x7fba40f41000</span><span class="w">   </span><span class="mh">0x218000</span><span class="w">        </span><span class="mh">0x0</span><span class="w"> </span>/dev/shm/...<span class="w">
</span></code></pre></div></div> <p>Alright, getting somewhere. I have no idea why <code class="language-plaintext highlighter-rouge">info shared</code> failed but <code class="language-plaintext highlighter-rouge">info proc mappings</code> did not. We want to find a mapping around the address <code class="language-plaintext highlighter-rouge">0x00007fbaa4653c30</code>.</p> <p>Found something.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mh">0x7fbaa4647000</span><span class="w">     </span><span class="mh">0x7fbaa4659000</span><span class="w">    </span><span class="mh">0x12000</span><span class="w">     </span><span class="mh">0x3000</span><span class="w"> </span>/usr/lib/x86_64-linux-gnu/libgcc_s.so.1<span class="w">
</span></code></pre></div></div> <p>The difference between the base address and our <code class="language-plaintext highlighter-rouge">$pc</code> is <code class="language-plaintext highlighter-rouge">0xcc30</code>. Add the offset <code class="language-plaintext highlighter-rouge">0x3000</code> to get <code class="language-plaintext highlighter-rouge">0xfc30</code>.</p> <div class="language-session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$ addr2line -e /usr/lib/x86_64-linux-gnu/libgcc_s.so.1 0xfc30</span><span class="w">
</span>??;0<span class="w">
</span></code></pre></div></div> <p>Okay well thx.</p> <div class="language-session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$ objdump -d -S /usr/lib/x86_64-linux-gnu/libgcc_s.so.1</span><span class="w">
</span>...<span class="w">
</span>fc30:<span class="w">       </span>80<span class="w"> </span>38<span class="w"> </span>48<span class="w">                </span>cmpb<span class="w">   </span>$0x48,(%rax)<span class="w">
    </span>fc33:<span class="w">       </span>0f<span class="w"> </span>85<span class="w"> </span>57<span class="w"> </span>ff<span class="w"> </span>ff<span class="w"> </span>ff<span class="w">       </span>jne<span class="w">    </span>fb90<span class="w"> </span>&lt;_Unwind_GetTextRelBase@@GCC_3.0+0xe40&gt;<span class="w">
    </span>fc39:<span class="w">       </span>48<span class="w"> </span>ba<span class="w"> </span>c7<span class="w"> </span>c0<span class="w"> </span>0f<span class="w"> </span>00<span class="w"> </span>00<span class="w">    </span>movabs<span class="w"> </span>$0x50f0000000fc0c7,%rdx<span class="w">
    </span>...<span class="w">
</span></code></pre></div></div> <p>Okay this wasn’t super useful. This is just some GCC unwinding utility function after a segfault. At this point, I just decide to examine the entire stack.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) x/128xg 0x7fff678eba00</span><span class="w">
</span>...<span class="w">
</span><span class="mh">0x7fff678eba00</span>:<span class="w"> </span><span class="mh">0x00007fba82086040</span><span class="w">      </span><span class="mh">0x00007fbaa465000b</span><span class="w">
</span><span class="mh">0x7fff678eba10</span>:<span class="w"> </span><span class="mh">0x000000000000002e</span><span class="w">      </span><span class="mh">0x0000000000000000</span><span class="w">
</span><span class="mh">0x7fff678eba20</span>:<span class="w"> </span><span class="mh">0x0000000000000000</span><span class="w">      </span><span class="mh">0x0000000000000000</span><span class="w">
</span><span class="mh">0x7fff678eba30</span>:<span class="w"> </span><span class="mh">0x00007fff678eced8</span><span class="w">      </span><span class="mh">0xb741446eb7f0e800</span><span class="w">
</span><span class="mh">0x7fff678eba40</span>:<span class="w"> </span><span class="mh">0x00007fff678eceb0</span><span class="w">      </span><span class="mh">0x00007fff678ebb50</span><span class="w">
</span><span class="mh">0x7fff678eba50</span>:<span class="w"> </span><span class="mh">0x00007fff678ebbf8</span><span class="w">      </span><span class="mh">0x00007fff678ebb50</span><span class="w">
</span><span class="mh">0x7fff678eba60</span>:<span class="w"> </span><span class="mh">0x00007fff678ebe00</span><span class="w">      </span><span class="mh">0x323338342034342d</span><span class="w">
</span>...<span class="w">
</span></code></pre></div></div> <p>Some patterns start to emerge. All values starting with <code class="language-plaintext highlighter-rouge">0x7fff</code> are pointers to things on the stack. Things in the range of <code class="language-plaintext highlighter-rouge">0x7fbaa..</code> are probably related to instructions. We can also see the junk value <code class="language-plaintext highlighter-rouge">0x3233</code> that was implicated in the segfault.</p> <h2 id="two-hours-later-">Two hours later …</h2> <p>My approach was to examine the stack visually, find pointers with prefixes that I knew to map to code I wore, and try and dereference them to get an idea of where my program was when it crashed.</p> <p>This is doable, but it is not as straightforward as you might think. The <em>why</em> requires going into how ELF binaries/shared libraries are loaded in the memory.</p> <ol> <li>There is a <code class="language-plaintext highlighter-rouge">/proc/&lt;pid&gt;/map</code> corresponding to <code class="language-plaintext highlighter-rouge">info proc mappings</code> that we saw earlier.</li> <li>Each ELF file is divided into segments, which are further divided into sections. Mapping happens at the granularity of a segment.</li> <li>The mapped segment will have a different offset than the on-disk segment. This may have something to do with alignment and/or ASLR requirements. But the segment sizes are also different for me, between what is reported by gdb, and what is shown by <code class="language-plaintext highlighter-rouge">readelf/objdump</code>.</li> </ol> <p>As a result, I was unable to map symbol addresses from the core dump to symbols in libraries effectively. There is theoretically no reason why gdb should not be able to do this automatically, and it does, for more benign cases. But it does not seem to load the shared libraries for me for this particular crash.</p> <h2 id="wait-">Wait …</h2> <p>Okay, I ran gdb with this specific sequence, and suddenly it chose to load shared libraries.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$<span class="w"> </span>gdb<span class="w">
</span><span class="gp">(gdb) set auto-solib-add off # do not auto-load solibs</span><span class="w">
</span><span class="gp">(gdb) set substitute-path /dev/shm /dev/null # something for shm maps</span><span class="w">
</span><span class="gp">(gdb) set solib-search-path /path/to/lib</span><span class="w">
</span><span class="gp">(gdb) file /path/to/my/binary</span><span class="w">
</span><span class="gp">(gdb) target core /path/to/core-file</span><span class="w">
</span><span class="gp">(gdb) info sharedlibrary</span><span class="w">
</span><span class="gp">(gdb) info sharedlibrary</span><span class="w">
</span>From<span class="w">                </span>To<span class="w">                  </span>Syms<span class="w"> </span>Read<span class="w">   </span>Shared<span class="w"> </span>Object<span class="w"> </span>Library<span class="w">
</span><span class="mh">0x00007fbaa4e98350</span><span class="w">  </span><span class="mh">0x00007fbaa4eaccd1</span><span class="w">  </span>No<span class="w">          </span>/lib/libx.so<span class="w"> 
</span><span class="mh">0x00007fbaa4e21a00</span><span class="w">  </span><span class="mh">0x00007fbaa4e72bc9</span><span class="w">  </span>No<span class="w">          </span>/lib/liby.so<span class="w">
</span>...<span class="w">
</span><span class="gp">(gdb) sharedlibrary /path/to/libmycode.so</span><span class="w">
</span>Reading<span class="w"> </span>symbols<span class="w"> </span>from<span class="w"> </span>...<span class="w">
</span></code></pre></div></div> <p>I have no idea which of the above did the trick. Consider it a magic sequence of commands for now.</p> <p>The game plan now is to go through the stack with <code class="language-plaintext highlighter-rouge">x/64xg $pc</code> and beyond to look for familiar addresses and try to resolve them via the symbol table. I tried a bunch of random symbols, and finally hit jackpot.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) info symbol 0x00005585a6470c80</span><span class="w">
</span>Serialize[...]<span class="w"> </span>in<span class="w"> </span>section<span class="w"> </span>.text<span class="w"> </span>of<span class="w"> </span>/my/binary<span class="w">
</span></code></pre></div></div> <p>It was a buffer overflow in a serialization routine.</p> <h2 id="conclusions">Conclusions</h2> <p>The battle between you and a coy acting core dump is a battle of wills. Do not blink.</p>]]></content><author><name></name></author><category term="systems"/><category term="gdb"/><summary type="html"><![CDATA[On the applications of fuzzy human pattern matching to extract secrets from a corrupted core dump in the age of trillion parameter AI]]></summary></entry><entry><title type="html">Using perf probes to intercept variables</title><link href="https://anku94.github.io/blog/2024/perf-inspect-vars/" rel="alternate" type="text/html" title="Using perf probes to intercept variables"/><published>2024-05-29T22:12:07+00:00</published><updated>2024-05-29T22:12:07+00:00</updated><id>https://anku94.github.io/blog/2024/perf-inspect-vars</id><content type="html" xml:base="https://anku94.github.io/blog/2024/perf-inspect-vars/"><![CDATA[<p><a href="">Part 1</a> and <a href="">Part 2</a> of this series at the respective links.</p> <p>This is a case study in using perf probes to monitor the values of some variable from a process, without having to modify its code.</p> <p>We are interested in monitoring the number of objects allocated by a library called <code class="language-plaintext highlighter-rouge">psm</code>. We know that they are available in a function called <code class="language-plaintext highlighter-rouge">psm_mpool_get</code>. The object available there is called <code class="language-plaintext highlighter-rouge">mp</code> and it has members <code class="language-plaintext highlighter-rouge">mp_num_obj</code> and <code class="language-plaintext highlighter-rouge">mp_num_obj_inuse</code> that we want to monitor.</p> <p>First, set up your permissions.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">sudo </span>addgroup tracing
<span class="nb">sudo </span>usermod <span class="nt">-aG</span> ankush tracing
newgrp tracing <span class="c"># "activate" group without having to log out</span>
<span class="nb">sudo </span>mount <span class="nt">-o</span> remount,mode<span class="o">=</span>755 /sys/kernel/debug
<span class="nb">sudo </span>mount <span class="nt">-o</span> remount,mode<span class="o">=</span>755 /sys/kernel/debug/tracing
<span class="nb">echo </span>0 | <span class="nb">sudo tee</span> /proc/sys/kernel/kptr_restrict
<span class="nb">echo</span> <span class="nt">-1</span> | <span class="nb">sudo tee</span> /proc/sys/kernel/perf_event_paranoid
<span class="nb">sudo chown </span>root:tracing /sys/kernel/debug/tracing/uprobe_events
<span class="nb">sudo chmod </span>g+rw /sys/kernel/debug/tracing/uprobe_events
</code></pre></div></div> <p>Next, we execute these commands to explore the available perf points and tap into them</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PSM</span><span class="o">=</span>/path/to/libpsm_infinipath.so

perf probe <span class="nt">-x</span> <span class="nv">$PSM</span> <span class="nt">--funcs</span> <span class="c"># lists probe-able functions</span>
perf probe <span class="nt">-x</span> <span class="nv">$PSM</span> <span class="nt">--funcs</span> | <span class="nb">grep </span>psmi_mpool_get <span class="c"># this is present</span>
perf probe <span class="nt">-x</span> <span class="nv">$PSM</span> <span class="nt">-L</span> psmi_mpool_get <span class="c"># view the source for this function</span>
perf probe <span class="nt">-x</span> <span class="nv">$PSM</span> <span class="nt">--vars</span> psmi_mpool_get <span class="c"># view available vars here.</span>

<span class="c"># mp is available in psmi_mpool_get</span>

<span class="c"># need mp-&gt;mp_num_obj and mp-&gt;mp_num_obj_inuse</span>
perf probe <span class="nt">-x</span> <span class="nv">$PSM</span> <span class="s1">'psm:nobj=psmi_mpool_get mp-&gt;mp_num_obj'</span>
perf probe <span class="nt">-x</span> <span class="nv">$PSM</span> <span class="s1">'psm:nused=psmi_mpool_get mp-&gt;mp_num_obj_inuse'</span>
</code></pre></div></div> <p>List active probes to confirm that they got added</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ perf probe -l
  psm:nobj             (on psmi_mpool_get@src/psm/psm_mpool.c in ...&gt;
  psm:nused            (on psmi_mpool_get@src/psm/psm_mpool.c in ...&gt;
</code></pre></div></div> <p>Start recording for all probes.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>perf record <span class="nt">-e</span> psm:nobj <span class="nt">-e</span> psm:nused <span class="nt">-a</span>
<span class="c"># run code from a different tab</span>
^C
perf script <span class="c"># this will show us what was emitted</span>
</code></pre></div></div> <p>Output:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> bin-using-psm 381026 [002] 417634.233519: psm:nused: (7f9980230350) mp_num_obj_inuse=0x0
 bin-using-psm 381027 [003] 417634.233519: psm:nused: (7fcc080f5350) mp_num_obj_inuse=0x0
 bin-using-psm 381028 [004] 417634.233519: psm:nused: (7fc05836e350) mp_num_obj_inuse=0x0
 bin-using-psm 381027 [003] 417634.233522:  psm:nobj: (7fcc080f5350) mp_num_obj=0x400
 bin-using-psm 381028 [004] 417634.233522:  psm:nobj: (7fc05836e350) mp_num_obj=0x400
 bin-using-psm 381026 [002] 417634.233522:  psm:nobj: (7f9980230350) mp_num_obj=0x400
 bin-using-psm 381029 [005] 417634.233523: psm:nused: (7fa818f52350) mp_num_obj_inuse=0x0
 bin-using-psm 381029 [005] 417634.233525:  psm:nobj: (7fa818f52350) mp_num_obj=0x400
 bin-using-psm 381030 [006] 417634.233525: psm:nused: (7f69a6c35350) mp_num_obj_inuse=0x0
 bin-using-psm 381030 [006] 417634.233527:  psm:nobj: (7f69a6c35350) mp_num_obj=0x400
</code></pre></div></div> <p>Bingo — we have the data. Other things:</p> <ol> <li>We can point <code class="language-plaintext highlighter-rouge">perf record</code> to a particular PID to record its values.</li> <li>We can process the data via say python using <code class="language-plaintext highlighter-rouge">perf script -g python</code></li> </ol> <p>Something like this will show the number of occurrences in real time, but AFAIK, can not show data embedded in the probe.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>perf <span class="nb">stat</span> <span class="nt">-a</span> <span class="nt">-e</span> psm:nobj <span class="nt">-I</span> 1000
</code></pre></div></div> <h3 id="references">References</h3>]]></content><author><name></name></author><category term="perf"/><category term="perf"/><summary type="html"><![CDATA[Intercept process variables without having to modify it]]></summary></entry><entry><title type="html">On Intelligence: Assessment and Directions</title><link href="https://anku94.github.io/blog/2024/llm-intelligence/" rel="alternate" type="text/html" title="On Intelligence: Assessment and Directions"/><published>2024-05-15T05:53:05+00:00</published><updated>2024-05-15T05:53:05+00:00</updated><id>https://anku94.github.io/blog/2024/llm-intelligence</id><content type="html" xml:base="https://anku94.github.io/blog/2024/llm-intelligence/"><![CDATA[<p>So the topic for this post is a bit of a departure from my usual mucking in the sewers that modern systems are. I have been fascinated by LLMs, and what they are missing enroute to “AGI”. This is a collection of some of those thoughts that have been brewing over the past few months. I am not particularly familiar with the related work in this area, and this is mostly coming from first principles, with some random inputs from here and there folded in.</p> <p>I have no calibration for how much of this is just me reiterating what is already known and well-understood, or obvious, or deeply flawed.</p> <h2 id="llms-as-currently-designed-can-not-be-reasoning">LLMs, As Currently Designed, Can Not Be Reasoning</h2> <p>This idea emerged in my head in the early days of GPT-3. Its prowess was shocking, and everyone started reassessing everything (<em>autogaslighting</em>). And then we started noticing a million ways to “crack” it, relaxed a little, and things got better with GPT-4/4o.</p> <p>This intuition is simple — LLMs generate text at a constant token rate, and an intelligent agent simply can not do that. For a simple query, an intelligent agent is able to respond instantly, while for a complex query, it needs to go and <em>think</em> and <em>plan</em> a response. There can not be any upper bound to the amount of time this takes.</p> <p>LLMs seem to encode some constant amount of capability. It is perfectly okay for a new (yet not fully optimized architecture that is on the right track) to take more time than necessary for a simple query, but an architecture that can not take an infinite time can not be reasoning.</p> <p>I have come across the term “out-of-distribution” to describe hallucination etc, and I think it offers a good way to think about LLMs — they form a distribution over all that is known, and are able to generate samples from that distribution. For why this does not amount to reasoning, read on and I think you will have a better idea of how this is going.</p> <h2 id="llms-as-a-snapshot-of-intuition">LLMs as a Snapshot of Intuition</h2> <p>I think LLMs are a lot more similar to <em>intuition</em>. Intuition is the mechanism by which we generate instant responses — these can be right, or wrong. I say <em>a snapshot of intuition</em> because human intuition constantly refines itself, and model weights are static.</p> <p>Intuition is a different property from <em>planning</em> and <em>reasoning</em>. I will describe this more in the “human learning” section — I feel that there are circular dependencies here and I can not seem to figure out a great order to put this in.</p> <p>Drawing an equivalence between LLMs and intuition has two interesting corollaries:</p> <ol> <li>It provides an explanation for why we are building massive and expensive models. This is somewhat similar to building an intuition so strong that you make up for an inability to reason.</li> <li>It maps them to a component of the grand architecture of “human cognitive ability”. This would imply that while we (as the human race) have not yet figured out the entire architecture, this is fundamentally similar to a building block.</li> </ol> <p>I do feel that the fundamental approach to synthesizing “capability” by “exposing” a neural network to lots of data is valid and powerful. This is in contrast to coding and program synthesis, where “capability” is hand-crafted line-by-line. This is not to say that the latter approaches are not valid, but that the former allows for capabilities the latter does not (and vice-versa), and seems to mirror aspects of the elusive human intelligence.</p> <h3 id="a-model-of-human-intelligence">A Model of Human Intelligence</h3> <p>I think my point should make a lot more sense if I explain my model of human intelligence.</p> <p>Say a “rational” human being is asked a question (say a physics situation involving some bodies). This is the sequence of steps they take:</p> <ol> <li>They have an initial intuition of how they expect the system to behave.</li> <li>They try to formally solve it by modeling it as a set of equations, solve the equations, and get a result.</li> <li>Let us pretend that they get a result that they believe is “counterintuitive”. They recheck their math and if it holds, accept that “while my intuition suggests otherwise, this must be true.”</li> <li>Over time, their intuition internalizes what the math says, and a year later if they are asked a similar question, their instinct is a lot closer.</li> </ol> <p>Now we can define <em>reasoning</em> and <em>planning</em>.</p> <ul> <li><em>Reasoning</em> is just modeling a situation as a set of logical statements, and them symbolically validating those statements.</li> <li><em>Planning</em> is decomposing a problem into a series of subproblems, possibly recursively, and solving the smaller subproblems, and composing all the leaf nodes into a solution for the bigger problem. <ul> <li>The “plan” for an “agent” can include “actions”. Over the course of trying to solve a problem, they may ask other agents for assistance, build machines, or take any other action within its scope.</li> </ul> </li> </ul> <p>“Agents” also “meta-reason” and “meta-intuit”. They think about whether their plan is logically valid or not. They have different preference profiles over the set of candidate actions. (Some are more likely to approach other agents, others may prefer choosing goals that avoid interactions etc.) These heuristics lead to emergent traits such as personality, extroversion, neuroticism etc.</p> <h2 id="a-lesson-from-flight">A Lesson from Flight</h2> <p>Now how does all this apply to how to build such capabilities? That is the quadrillion dollar question.</p> <p>How humans cracked flight is, in my opinion, an instructive parallel. That birds could fly established that flight is possible. However, the mechanics we use to actually fly are very different — our aircraft do not flap their wings. We probably still can not build a meaningful wing-flapping aircraft. That in no way limits our ability to leverage aviation and structure our entire economies around that capability being commonplace.</p> <p>The same holds for LLMs. They need <em>reasoning</em> and <em>planning</em>, but the way they achieve these capabilities may be very different from the way we evolved. Life evolved as a self-sustaining Minimal Viable Product that could mutate to gain capabilities. We may be able to stitch together a “self-sustaining cognitive loop” directly from larger pieces. Or we may find that the easier way to do it is to build simpler agents and let them self-mutate to acquire capability.</p> <p>I think a variety of architectures are possible — autonomous and not. It is not necessary that they are conscious, “alive”, have free will, have feelings, etc.</p> <h2 id="a-lesson-from-organic-chemistry">A Lesson from Organic Chemistry</h2> <p>Before the 18th century, we believed that certain molecules, associated with living beings, had an inherent life force, and therefore could not be synthesized artificially. From Wikipedia:</p> <blockquote> <p>In 1828 <a href="https://en.wikipedia.org/wiki/Friedrich_W%C3%B6hler" title="Friedrich Wöhler">Friedrich Wöhler</a> produced the <em>organic</em> chemical <a href="https://en.wikipedia.org/wiki/Urea" title="Urea">urea</a> (carbamide), a constituent of <a href="https://en.wikipedia.org/wiki/Urine" title="Urine">urine</a>, from <em>inorganic</em> starting materials (the salts <a href="https://en.wikipedia.org/wiki/Potassium_cyanate" title="Potassium cyanate">potassium cyanate</a> and <a href="https://en.wikipedia.org/wiki/Ammonium_sulfate" title="Ammonium sulfate">ammonium sulfate</a>), in what is now called the <a href="https://en.wikipedia.org/wiki/W%C3%B6hler_synthesis" title="Wöhler synthesis">Wöhler synthesis</a>.</p> </blockquote> <p>It was then that we realized that organic molecules have nothing inherently different from others. They could be synthesized, hacked, and novel ones could be created to trick our bodies into working a certain way.</p> <p>I think that to the extent we think about intelligence as something inherent to humans, we will shortly be proven wrong. I also think that it will be less of a breakthrough moment than a series of continual improvements of the kind we are currently in the midst of — deeply shaping the way we work and organize human productivity along the way.</p>]]></content><author><name></name></author><category term="ml"/><category term="ml"/><category term="llm"/><category term="aligners"/><summary type="html"><![CDATA[How far have LLMs gotten us? What remains? What will "the rest" take?]]></summary></entry><entry><title type="html">An Exercise In Debugging When The Kernel Is Implicated</title><link href="https://anku94.github.io/blog/2024/quis-custodiet/" rel="alternate" type="text/html" title="An Exercise In Debugging When The Kernel Is Implicated"/><published>2024-04-15T20:22:10+00:00</published><updated>2024-04-15T20:22:10+00:00</updated><id>https://anku94.github.io/blog/2024/quis-custodiet</id><content type="html" xml:base="https://anku94.github.io/blog/2024/quis-custodiet/"><![CDATA[<p>Situation: an MPI application (10s of processes) seems to freeze after completion. Once it freezes, I can’t attach to any of its processes via <code class="language-plaintext highlighter-rouge">gdb -p</code> (that also freezes). I can’t <code class="language-plaintext highlighter-rouge">SIGTERM</code> or even <code class="language-plaintext highlighter-rouge">SIGKILL</code> the processes. <code class="language-plaintext highlighter-rouge">ps aux</code> (my standard set of ps flags) shows the processes in either an <code class="language-plaintext highlighter-rouge">Is</code> state, or a <code class="language-plaintext highlighter-rouge">Ds</code> state.</p> <p>Apparently, <code class="language-plaintext highlighter-rouge">D</code> processes are waiting for I/O in a non-interruptible state. <code class="language-plaintext highlighter-rouge">I</code> processes are idle, and are in an interruptible state. If I tried to poke around in <code class="language-plaintext highlighter-rouge">/proc/&lt;pid&gt;</code> too much, even procfs would freeze.</p> <h2 id="wchan">wchan</h2> <p>The first useful thing I learned was the <code class="language-plaintext highlighter-rouge">wchan</code> column in <code class="language-plaintext highlighter-rouge">ps</code>. <code class="language-plaintext highlighter-rouge">wchan</code> means wait channel - it tells you what stream (or whatever the definition of a channel is) is a process waiting on.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ -eo ppid,pid,user,stat,pcpu,comm,wchan -p 21061 | grep stoch
  21028   21060 ankushj  Zs    0.3 stoch &lt;defunct&gt; -
  21028   21061 ankushj  Is    0.4 stochastic_subg ptlrpc_set_wait
  21028   21062 ankushj  Zs    0.2 stoch &lt;defunct&gt; -
  21028   21068 ankushj  Zs    0.2 stoch &lt;defunct&gt; -
  21028   21069 ankushj  Ds    0.4 stochastic_subg rwsem_down_write_slowpath
  21028   21070 ankushj  Ds    0.4 stochastic_subg rwsem_down_write_slowpath
  21028   21071 ankushj  Zs    0.4 stoch &lt;defunct&gt; -
  21028   21072 ankushj  Zs    0.4 stoch &lt;defunct&gt; -
  ...
</code></pre></div></div> <p>Bingo - we have some function names to blame. Apparently we can get more context around these without needing to attach a debugger, which we can not.</p> <p>We can <code class="language-plaintext highlighter-rouge">cat</code> <code class="language-plaintext highlighter-rouge">/proc/&lt;pid&gt;/stack</code> to get a stack trace from a process without a debugger. Thankfully this works.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo cat /proc/21061/stack

[&lt;0&gt;] ptlrpc_set_wait+0x5e8/0x730 [ptlrpc]
[&lt;0&gt;] ptlrpc_queue_wait+0x88/0x230 [ptlrpc]
[&lt;0&gt;] ldlm_cli_enqueue+0x436/0x990 [ptlrpc]
[&lt;0&gt;] mdc_enqueue_base+0x2f2/0x1c90 [mdc]
[&lt;0&gt;] mdc_intent_lock+0x212/0x530 [mdc]
[&lt;0&gt;] lmv_intent_lock+0x385/0x16b0 [lmv]
[&lt;0&gt;] ll_lookup_it+0x7ad/0x20e0 [lustre]
[&lt;0&gt;] ll_atomic_open+0x198/0xff0 [lustre]
[&lt;0&gt;] lookup_open+0x364/0x6e0
[&lt;0&gt;] do_last+0x2cb/0x900
[&lt;0&gt;] path_openat+0x8d/0x290
[&lt;0&gt;] do_filp_open+0x91/0x100
[&lt;0&gt;] do_sys_open+0x17e/0x290
[&lt;0&gt;] __x64_sys_openat+0x20/0x30
[&lt;0&gt;] do_syscall_64+0x57/0x190
[&lt;0&gt;] entry_SYSCALL_64_after_hwframe+0x44/0xa9
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo cat /proc/21065/stack

[&lt;0&gt;] rwsem_down_write_slowpath+0x244/0x4d0
[&lt;0&gt;] do_last+0x2b1/0x900
[&lt;0&gt;] path_openat+0x8d/0x290
[&lt;0&gt;] do_filp_open+0x91/0x100
[&lt;0&gt;] do_sys_open+0x17e/0x290
[&lt;0&gt;] __x64_sys_openat+0x20/0x30
[&lt;0&gt;] do_syscall_64+0x57/0x190
[&lt;0&gt;] entry_SYSCALL_64_after_hwframe+0x44/0xa9
</code></pre></div></div> <p>This is beautiful! Instead of gaslighting ourselves and slipping into an existential crisis, we can point our fingers elsewhere.</p> <h2 id="conclusion">Conclusion</h2> <p>Both these stack traces indicate getting stuck on a File I/O call. The first trace is more specific - it tells us that it is a Lustre I/O. Lustre is a parallel filesystem.</p> <p>Turns out that one of my Lustre OSTs was dead. That would explain this behavior - the Lustre module sits in the kernel, and is blocked trying to reach that OST. Maybe there are good reasons a timeout there can not be handled gracefully, maybe there are not. But a kernel module freezing is tough - a whole bunch of debugging options go for a toss. Thankfully some still work!</p>]]></content><author><name></name></author><category term="debugging"/><category term="#systems"/><category term="#gdb"/><summary type="html"><![CDATA[The problem here was being caused by a kernel module misbehaving because a remote service was misbehaving.]]></summary></entry><entry><title type="html">Replication Part 1 - Primary-Backup vs Chain Replication</title><link href="https://anku94.github.io/blog/2024/replication-part-1/" rel="alternate" type="text/html" title="Replication Part 1 - Primary-Backup vs Chain Replication"/><published>2024-04-11T17:35:30+00:00</published><updated>2024-04-11T17:35:30+00:00</updated><id>https://anku94.github.io/blog/2024/replication-part-1</id><content type="html" xml:base="https://anku94.github.io/blog/2024/replication-part-1/"><![CDATA[<p>The purpose with this series of posts, to the extent it is followed through, is to arrive at different replication schemes by applying diffs to some well-understood schemes. This exercise should help us understand the tradeoffs, the design space, and reason about whether a point in the design space is pareto-optimal, that is, can its pros be realized by a diff over some other design point with less cons.</p> <p>This is somewhat facetious, but IMO there are two classes of people in the distributed systems world — Leslie Lamport, who stared into the soul of replication and figured out something fundamental a couple of decades ago and has since been trying to tell us all that everything in replication is a specialization of that [principle][1,2,3], and everyone else.</p> <p>Part 1 will cover 3 basic designs. For now, we will assume single-key operations and key-value semantics, and see how far this simple model gets us.</p> <p>Let me also try to assign relative perf numbers for these, where 100 is the max perf for a single-node design (writes and reads are assumed to be symmetric cost-wise, so a 100 perf for writes and reads just means that any combination of the two will have a perf of 100. Perf = latency = throughput as we can assume one request in flight at a time, WLOG?). So a perf of 500 implies 5X the read throughput of a single node.</p> <h5 id="1-a-single-worker">1. A Single Worker</h5> <p>(Worker could be a core, or a node, or a datacenter even. We relax consistency for performance all the way down.)</p> <p>Design: a single worker, receives all requests, applies them sequentially, writes see reads, works great, no issues.</p> <p>Consistency: Strict Failure: No tolerance Read Perf: 100 Write Perf: 100</p> <h5 id="2-primary-backup">2. Primary-Backup</h5> <p>Two workers. All requests are handled by the primary. All writes are synchronously copied to backup. Backup kicks in on failure.</p> <p>Consistency: Strict Failure: Tolerates 1 Read Perf: 100 Write Perf: 50 (assuming synchronous copying = as costly as query)</p> <h5 id="2a-primary-backup-with-async-replication">2a. Primary-Backup with Async Replication</h5> <p>Primary can ACK to a request before replication to backup is completed. It is a meaningless design point because async replication has no tolerance for failures. The delta between the two can be lost.</p> <h5 id="2b-primary-backup-with-backup-serving-reads">2b. Primary-Backup with Backup Serving Reads</h5> <p>The backup is right there, and it is idle. Can we use it?</p> <p>We won’t use it for writes, because concurrent writes to the same key can cause conflicts and we do not yet know how to resolve them. Also we have not evolved and coordination mechanism yet. But we could use it for reads… right?</p> <p>But it should respond to reads without requiring coordination with the primary, otherwise we have not really gained anything in terms of performance. But that has consistency implications — what if the primary is concurrently updating the value we returned?</p> <p>This works under two cases:</p> <ol> <li>A looser consistency model, Sequential Consistency, is acceptable, OR</li> <li>The Primary and Backup can establish a coordination mechanism that is more efficient than what the clients can do (sharding keys is one example of such a mechanism)</li> </ol> <p>For case 2b1.</p> <p>Consistency: Sequential Failure: Tolerates 1 Read Perf: 200 Write Perf: 50</p> <h5 id="3-chain-replication">3. Chain Replication</h5> <p>Chain Replication is just a generalization of 2b. Instead of having one replica, you can have N replicas. In fact, for 1:N primary-read serving backup systems, I think these two are logically equivalent:</p> <ol> <li>The primary chaining writes sequentially through replicas</li> <li>The primary broadcasting writes to all replicas</li> </ol> <p>First option increases latency by N, and the second option requires the primary to do $N\times$ more communication.</p> <p>I think the two only have perf implications, but are logically equivalent to each other and to 2b.</p> <h4 id="references">References</h4>]]></content><author><name></name></author><category term="systems"/><summary type="html"><![CDATA[Simplifying scheme soup with successive steps]]></summary></entry><entry><title type="html">Journey Through A CMake Dependency Problem</title><link href="https://anku94.github.io/blog/2024/journey-thru-a-cmake/" rel="alternate" type="text/html" title="Journey Through A CMake Dependency Problem"/><published>2024-02-22T20:17:06+00:00</published><updated>2024-02-22T20:17:06+00:00</updated><id>https://anku94.github.io/blog/2024/journey-thru-a-cmake</id><content type="html" xml:base="https://anku94.github.io/blog/2024/journey-thru-a-cmake/"><![CDATA[<p>Situation: I have a CMake project that needs <code class="language-plaintext highlighter-rouge">libfabric</code>, which needs <code class="language-plaintext highlighter-rouge">rdma-core</code>.</p> <p>Both of these are non-CMake Projects, but they generate <code class="language-plaintext highlighter-rouge">pkg-config</code> files in <code class="language-plaintext highlighter-rouge">/prefix/lib/pkg-config</code>.</p> <p><strong>Q. How to locate these libraries as dependencies in my CMake project?</strong></p> <p>A. Use CMake’s <code class="language-plaintext highlighter-rouge">PkgConfig</code> package.</p> <pre><code class="language-CMake">find_package(PkgConfig)
pkg_check_modules(LIBFABRIC REQUIRED IMPORTED_TARGET GLOBAL libfabric&gt;=1.14)

if (LIBFABRIC_FOUND)
  message(STATUS "LIBFABRIC_INCLUDE_DIRS: ${LIBFABRIC_INCLUDE_DIRS}")
  message(STATUS "LIBFABRIC_LIBRARY_DIRS: ${LIBFABRIC_LIBRARY_DIRS}")
else()
  message(FATAL_ERROR "LIBFABRIC not found.")
endif()

target_link_libraries(exec PRIVATE PkgConfig::LIBFABRIC)
# Side note: I don't know what GLOBAL does
# I thought it'd get the target out of the pkg-config namespace. Apparently not.
</code></pre> <p><strong>Q. Ok, code was built, but it can not locate libraries at the custom path.</strong></p> <p>A. You could use <code class="language-plaintext highlighter-rouge">LD_LIBRARY_PATH</code>, but that’s honestly annoying. With <code class="language-plaintext highlighter-rouge">RPATH/RUNPATH</code>, your binary knows where to find the packages it was linked to.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ldd exec
        linux-vdso.so.1 (0x00007ffe733f7000)
        libfabric.so.1 =&gt; /opt/fi_bench/libfabric/fab-prefix/lib/libfabric.so.1 (0x00007ff4d8924000)
        libstdc++.so.6 =&gt; /lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007ff4d873b000)
        libgcc_s.so.1 =&gt; /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007ff4d8720000)
        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007ff4d852e000)
        libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007ff4d8526000)
        librdmacm.so.1 =&gt; not found
        libibverbs.so.1 =&gt; not found
        libnuma.so.1 =&gt; /lib/x86_64-linux-gnu/libnuma.so.1 (0x00007ff4d8519000)
        librt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007ff4d850e000)
        libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007ff4d84eb000)
        libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007ff4d839a000)
        /lib64/ld-linux-x86-64.so.2 (0x00007ff4d92ea000)
</code></pre></div></div> <p>Why can it not find <code class="language-plaintext highlighter-rouge">librdmacm.so.1</code> or <code class="language-plaintext highlighter-rouge">libibverbs.so.1</code>? We run <code class="language-plaintext highlighter-rouge">make VERBOSE=1</code> to intercept the compile command.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/usr/bin/c++ <span class="nt">-Wl</span>,-rpath,/opt/fi_bench/libfabric/rdma-core-50.0/build/lib CMakeFiles/server.dir/server_main.cpp.o CMakeFiles/server.dir/common.cc.o CMakeFiles/server.dir/fabric.cpp.o CMakeFiles/server.dir/endpoint.cpp.o CMakeFiles/server.dir/benchmark.cpp.o <span class="nt">-o</span> server  <span class="nt">-Wl</span>,-rpath,/opt/fi_bench/libfabric/fab-prefix/lib:/opt/fi_bench/libfabric/rdma-core-50.0/build/lib /opt/fi_bench/libfabric/fab-prefix/lib/libfabric.so /opt/fi_bench/libfabric/rdma-core-50.0/build/lib/libibverbs.so
</code></pre></div></div> <p>We see that the build process is supplying the relevant rpaths. Why are they not being resolved?</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ readelf -d executable | head

Dynamic section at offset 0x5c60 contains 31 entries:
  Tag        Type                         Name/Value
 0x0000000000000001 (NEEDED)             Shared library: [libfabric.so.1]
 0x0000000000000001 (NEEDED)             Shared library: [libstdc++.so.6]
 0x0000000000000001 (NEEDED)             Shared library: [libgcc_s.so.1]
 0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]
 0x000000000000001d (RUNPATH)            Library runpath: [/opt/fi_bench/libfabric/rdma-core-50.0/build/lib:/opt/fi_bench/libfabric/fab-prefix/lib:/opt/fi_bench/libfabric/rdma-core-50.0/build/lib]
</code></pre></div></div> <p>So apparently <code class="language-plaintext highlighter-rouge">server</code> does not have <code class="language-plaintext highlighter-rouge">libibverbs.so</code> as a dependency! So it doesn’t care about its rpath. It must be coming from <code class="language-plaintext highlighter-rouge">libfabric.so</code> then.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ldd libfabric.so.1
        librdmacm.so.1 =&gt; not found
        libibverbs.so.1 =&gt; not found
        libnuma.so.1 =&gt; /lib/x86_64-linux-gnu/libnuma.so.1 (0x00007f534861b000)
        librt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007f5348610000)
        libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f53485ed000)
        libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f53485e5000)
        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f53483f3000)
        /lib64/ld-linux-x86-64.so.2 (0x00007f5348fee000)
</code></pre></div></div> <p>Why does <code class="language-plaintext highlighter-rouge">libfabric</code> not preserve rpaths?</p> <p>At this point I don’t care. I just hacked the rpaths into LDFLAGS.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ verbs_PREFIX=$RDMA_PATH/build verbs_LIBDIR=$RDMA_PATH/build/lib LDFLAGS="-Wl,-rpath,$RDMA_PATH/build/lib" ./configure --prefix=/opt/fi_bench/libfabric/fab-prefix
</code></pre></div></div> <p>Afterwards,</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ldd libfabric.so
        linux-vdso.so.1 (0x00007ffecb1d0000)
        /users/ankushj/repos/stderred/build/libstderred.so (0x00007f9e73c24000)
        librdmacm.so.1 =&gt; /opt/fi_bench/libfabric/rdma-core-50.0/build/lib/librdmacm.so.1 (0x00007f9e73c07000)
        libibverbs.so.1 =&gt; /opt/fi_bench/libfabric/rdma-core-50.0/build/lib/libibverbs.so.1 (0x00007f9e73be5000)
        libnuma.so.1 =&gt; /lib/x86_64-linux-gnu/libnuma.so.1 (0x00007f9e73bd0000)
        librt.so.1 =&gt; /lib/x86_64-linux-gnu/librt.so.1 (0x00007f9e73bc5000)
        libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f9e73ba2000)
        libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f9e73b9a000)
        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f9e739a8000)
        libnl-3.so.200 =&gt; /lib/x86_64-linux-gnu/libnl-3.so.200 (0x00007f9e73985000)
        /lib64/ld-linux-x86-64.so.2 (0x00007f9e745e2000)
        libnl-route-3.so.200 =&gt; /lib/x86_64-linux-gnu/libnl-route-3.so.200 (0x00007f9e7390b000)
</code></pre></div></div> <p>You can love systems, rarely do they love you back.</p>]]></content><author><name></name></author><category term="systems"/><category term="systems,"/><category term="cmake"/><summary type="html"><![CDATA[Or how to craft artisan ELF files with exquisitely detailed metadata]]></summary></entry><entry><title type="html">Indian Union Budget - Expenditure Analysis</title><link href="https://anku94.github.io/blog/2023/govt-exp/" rel="alternate" type="text/html" title="Indian Union Budget - Expenditure Analysis"/><published>2023-11-11T04:35:31+00:00</published><updated>2023-11-11T04:35:31+00:00</updated><id>https://anku94.github.io/blog/2023/govt-exp</id><content type="html" xml:base="https://anku94.github.io/blog/2023/govt-exp/"><![CDATA[<p>Check <a href="https://anku94.github.io/dash/sankey">this</a> out! (Code <a href="https://github.com/anku94/dataviz">here</a>.)</p> <p>Government budgets are opaque. They utterly, absolutely, completely dwarf smaller social sector organizations trying to make anything better. They are also poorly understood.</p> <p>This is an attempt to demystify them - mostly for myself, maybe for others. This is also a WIP, and will (may?) get better over time. Understanding these datasets better helps us understand entrenched interest groups that have captured a disproportionate share of these sums (a typical pattern in democracies).</p> <p>Some quick notes on the process:</p> <ol> <li> <p>Indian govt. is organized as ministries, which are internally organized as departments. Some departments are directly managed by the PMO (I think?) and do not have a parent ministry as such. Each ministry creates multiple demands for grant, one for each department.</p> </li> <li> <p>I parsed a giant Excel sheet containing 100+ of these demands for grants, and organized them into a tree-like structure. This process was painful, and the python code that does this is a reflection of that. There are a couple of places where things get rounded off due to heuristics breaking down, but they should not cause massive issues.</p> </li> <li> <p>The data visualization in in a decent JS stack (NextJS, React, Typescript, Plotly.js …). Feel free to contribute!</p> </li> </ol>]]></content><author><name></name></author><category term="data"/><category term="js,"/><category term="goi"/><summary type="html"><![CDATA[Expenditure analysis and visualization of the Indian Govt. Union Budget for FY2023-24.]]></summary></entry><entry><title type="html">The Varied Flavors of Infiniband</title><link href="https://anku94.github.io/blog/2023/infiniband-flavors/" rel="alternate" type="text/html" title="The Varied Flavors of Infiniband"/><published>2023-09-11T19:05:42+00:00</published><updated>2023-09-11T19:05:42+00:00</updated><id>https://anku94.github.io/blog/2023/infiniband-flavors</id><content type="html" xml:base="https://anku94.github.io/blog/2023/infiniband-flavors/"><![CDATA[<p>This is an attempt to track and understand all the different “flavors” of Infiniband-like interfaces that are around, active, or relevant.</p> <p>Thinking of things like PSM, PSM2, OFI, Verbs, UCX etc. I doubt this particular post will have anything insightful — this is more of a placeholder for more insightful things in the future.</p> <h2 id="pre-historic-times-1995-2002">Pre-historic Times (1995-2002)</h2> <p>Most HPC clusters had proprietary networks, with their own <a href="https://agullo-teach.gitlabpages.inria.fr/school/school2019/slides/mpi.pdf">MPI providers</a>. Some weird-sounding names: MPICH-MX, MPICH-Elanlab.</p> <h2 id="ancient-times-1995-2002">Ancient Times (1995-2002)</h2> <p>InfiniBand: long awaited HPC network standard. Comes with OFED open-source networks stack, the <code class="language-plaintext highlighter-rouge">verbs</code> API. MPI implementations started using Verbs.</p> <h2 id="pre-modern-2005-2010-and-modern-2010-now-times">Pre-Modern (2005-2010) and Modern (2010-Now) Times</h2> <h3 id="performance-scaled-messaging">Performance-Scaled Messaging</h3> <p>Needs supposedly start outstripping the capabilities of the standards. PSM (Performance-Scaled Messaging) is introduced.</p> <h4 id="psm-owner-history">PSM Owner History</h4> <p>There used to be this company called QLogic. They developed network hardware, including “Infiniband”, in the pre-modern times.</p> <p>Their IB was compatible with the Verbs API, but was developed truly for this interface called PSM. They acquired PathScale (a compiler vendor, among other things maybe?) in 2006, and developed <em>InfiniPath</em>, also marketed as <em>TrueScale</em> — a network interface that was Infiniband-compatible but supported PSM for better performance.</p> <p>They were later sold to Intel. Their tech became the basis of a second-gen interconnect called <em>Omni-Path</em>. Omni-Path used an evolution of psm called psm2, which was not backward-compatible. The psm/Qlogic stuff was 40 Gbps, psm2/Omni-Path was 100 Gbps. As per <a href="https://www.nextplatform.com/2023/08/24/cornelis-unveils-ambitious-omni-path-interconnect-roadmap/">this</a>, Omni-Path also incorporated features from Gemini and Aries interconnects bought from Cray in 2012.</p> <p>Something happened at Intel around 2019 — they canceled the 200 Gbps variant of Omni-Path. In 2020, a company called Cornelis Networks was spun out to carry Omni-Path forward.</p> <p><a href="https://www.nextplatform.com/2021/07/09/a-third-dialect-of-infiniband-in-the-works-again/">Cornelis</a> still exists, and are continuing the development of Omni-Path-based products.</p> <h4 id="psm-technical-details">PSM Technical Details</h4> <p>This is more of questions and references.</p> <blockquote> <p>“The software infrastructure of InfiniBand, based on verbs, is really based on the original goals of InfiniBand, which was to replace PCI-X and Fibre Channel and maybe Ethernet,” Murphy tells The Next Platform. “Verbs were not structured at all for high performance computing. PathScale created Performance Scale Messaging, or PSM, which was totally independent of InfiniBand verbs and was a parallel transport layer specific focused on HPC. In the enterprise, when I am talking to 40 or 50 disk drives or 40 or 50 queue pairs, I can put that on my adapter’s cache and it works great. But in HPC, when I have a node with a hundred cores and a thousand nodes, this becomes a giant scalability problem we just cannot manage in the adapter’s cache. PSM could do this better, but even this was invented two decades ago and the world has continued to evolve.</p> </blockquote> <p>It seems one of the considerations for PSM was the NIC SRAM overhead of creating Verbs Queue Pairs. NIC SRAM is finite, and for all-to-all type communication patterns, the SRAM can not fit all the contexts. This <a href="https://www.usenix.org/system/files/conference/osdi16/osdi16-kalia.pdf">paper</a> also talks about prefering RDMA UDs over RCs. With RDMA UD, one queue pair can be used for multiple destinations, and the total number of QPs can be controlled. We don’t want CPU cores contending over UDs, so one QP/core is still desirable, but it scales with the number of cores, instead of the number of destinations, which is a lot more tractable for large clusters.</p> <p>One of the references also talks about dynamic congestion detection and rerouting borrowed from Aries and incorporated into Omni-Path. As per <a href="https://www.youtube.com/watch?v=E0uSl_gyZnI">this</a>: QLogic thought that the best way to provide scaling was to avoid hardware offload entirely, and have everything be done by building on efficient Host CPU-based primitives. Datacenter hardware trying to support TCP, as we know in hindsight, went in the opposite direction, and now we’re talking about DPUs and SmartNICs.</p> <h3 id="mellanox-and-nvidia">Mellanox and Nvidia</h3> <p>Something about Mellanox hacking Verbs, with “Accelerated Verbs”, MXM, UCX, RoCE, GPUDirect …</p> <h3 id="hpe-and-slingshot-and-ultraethernet">HPE and Slingshot and UltraEthernet</h3> <p>Similar stuff?</p> <h3 id="then-there-is-cxl">Then there is CXL</h3> <p>Phew.</p>]]></content><author><name></name></author><category term="systems"/><category term="networks"/><summary type="html"><![CDATA[Some description]]></summary></entry><entry><title type="html">Playing With Perf Probes - II</title><link href="https://anku94.github.io/blog/2023/more-perf/" rel="alternate" type="text/html" title="Playing With Perf Probes - II"/><published>2023-09-11T17:37:12+00:00</published><updated>2023-09-11T17:37:12+00:00</updated><id>https://anku94.github.io/blog/2023/more-perf</id><content type="html" xml:base="https://anku94.github.io/blog/2023/more-perf/"><![CDATA[<h3 id="problem-need-sudo-to-probe">Problem: Need Sudo To Probe</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>perf probe <span class="nt">-x</span> ./code <span class="nt">--add</span><span class="o">=</span><span class="s1">'add_with_sleep:0 sleep_us'</span>
</code></pre></div></div> <p>This will fail without <code class="language-plaintext highlighter-rouge">sudo</code> unless you’re root. A solid <a href="https://www.kdab.com/wp-content/uploads/stories/Linux_perf_for_Qt_developers.pdf">setup</a> that fixes most perf permissions issues:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">sudo </span>mount <span class="nt">-o</span> remount,mode<span class="o">=</span>755 /sys/kernel/debug
<span class="nb">sudo </span>mount <span class="nt">-o</span> remount,mode<span class="o">=</span>755 /sys/kernel/debug/tracing
<span class="nb">echo </span>0 | <span class="nb">sudo tee</span> /proc/sys/kernel/kptr_restrict
<span class="nb">echo</span> <span class="nt">-1</span> | <span class="nb">sudo tee</span> /proc/sys/kernel/perf_event_paranoid
<span class="nb">sudo chown </span>root:tracing /sys/kernel/debug/tracing/uprobe_events
<span class="nb">sudo chmod </span>g+rw /sys/kernel/debug/tracing/uprobe_events

</code></pre></div></div> <h3 id="probing-internal-library-functions">Probing Internal Library Functions</h3> <p>You’re going through the source code of your library, and there’s a specific internal function you want to profile. But it’s not listed in <code class="language-plaintext highlighter-rouge">perf probe -x exec -F</code>. It probably isn’t listed in <code class="language-plaintext highlighter-rouge">nm -a exec</code> either. If your functions are using this:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="n">__inline__</span> <span class="n">FN</span> <span class="nf">__attribute__</span><span class="p">((</span><span class="n">always_inline</span><span class="p">));</span>
</code></pre></div></div> <p>There’s no way they’re making it to the compiled output. This must be deleted. With <code class="language-plaintext highlighter-rouge">__inline__</code> and <code class="language-plaintext highlighter-rouge">inline</code>, things vary. There are two things I needed to get gcc to preserve my symbols up to the final <code class="language-plaintext highlighter-rouge">.so</code> object:</p> <ol> <li>Remove <code class="language-plaintext highlighter-rouge">always_inline</code> from code</li> <li>Add <code class="language-plaintext highlighter-rouge">-fvisibility=default</code> to my compiler flags</li> <li>Add <code class="language-plaintext highlighter-rouge">-fno-inline</code> to counter the anti-debugging forces channeled by <code class="language-plaintext highlighter-rouge">-O3</code></li> </ol> <p>More references:</p> <ul> <li><a href="https://minervadb.xyz/wp-content/uploads/2020/12/Dynamic-Tracing-for-Finding-and-Solving-MySQL-Performance-Problems-on-Linux-MinervaDB-Database-Platforms-Virtual-Conference-2020.pdf">MinervaDB</a></li> <li><a href="https://www.spinics.net/lists/linux-perf-users/msg02465.html">MailingList</a></li> </ul>]]></content><author><name></name></author><category term="systems"/><category term="perf"/><summary type="html"><![CDATA[Using perf probes for dynamic instrumentation]]></summary></entry><entry><title type="html">Playing With Perf Probes</title><link href="https://anku94.github.io/blog/2023/perf-probes/" rel="alternate" type="text/html" title="Playing With Perf Probes"/><published>2023-09-08T19:56:00+00:00</published><updated>2023-09-08T19:56:00+00:00</updated><id>https://anku94.github.io/blog/2023/perf-probes</id><content type="html" xml:base="https://anku94.github.io/blog/2023/perf-probes/"><![CDATA[<p>This post demonstrates the power of perf probes, using the following example C code. Let’s say we’d like to verify that usleep actually sleeps for the claimed amount of time. This is the output we can get.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Sleep Arg: 0 us, Sleep Time: 92 us
Sleep Arg: 100 us, Sleep Time: 167 us
Sleep Arg: 200 us, Sleep Time: 262 us
Sleep Arg: 300 us, Sleep Time: 370 us
Sleep Arg: 400 us, Sleep Time: 468 us
Sleep Arg: 500 us, Sleep Time: 584 us
Sleep Arg: 600 us, Sleep Time: 684 us
Sleep Arg: 700 us, Sleep Time: 784 us
Sleep Arg: 800 us, Sleep Time: 885 us
</code></pre></div></div> <p>Code for this exercise.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">add_with_sleep</span><span class="p">(</span><span class="kt">int</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="n">sleep_us</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">usleep</span><span class="p">(</span><span class="n">sleep_us</span><span class="p">);</span>
  <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">;</span>

<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">ret</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">ret</span> <span class="o">+=</span> <span class="n">add_with_sleep</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="o">*</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">100</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"I: %d, Ret: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">ret</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>Series of commands. You can run them line by line.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

setup<span class="o">()</span> <span class="o">{</span>
  <span class="nb">echo</span> <span class="nt">-1</span> | <span class="nb">sudo tee</span> /proc/sys/kernel/perf_event_paranoid
<span class="o">}</span>

run<span class="o">()</span> <span class="o">{</span>
  gcc <span class="nt">-g</span> <span class="nt">-o</span> code code.c
  ./code

  <span class="nb">alias </span><span class="nv">perf</span><span class="o">=</span>~/.local/bin/perf

  <span class="c"># -g enables call graph</span>
  perf record <span class="nt">-g</span> ./code

  <span class="c"># DWARF enables better stack unwinding</span>
  perf record <span class="nt">-g</span> <span class="nt">--call-graph</span><span class="o">=</span>dwarf ./code
  perf report <span class="nt">--stdio</span>

  <span class="c"># Show probe-able functions in binary</span>
  perf probe <span class="nt">-x</span> ./code <span class="nt">-F</span>

  <span class="c"># Show probe-able function lines in binary</span>
  perf probe <span class="nt">-x</span> ./code <span class="nt">-L</span> add_with_sleep

  <span class="c"># Show probe-able function lines in binary</span>
  perf probe <span class="nt">-x</span> ./code <span class="nt">-L</span> add_with_sleep:2

  <span class="c"># Show available variables at some point</span>
  perf probe <span class="nt">-x</span> ./code <span class="nt">-V</span> add_with_sleep:2

  <span class="c"># Add probes for function entry and exit. At entry, we also capture the arg.</span>
  <span class="c"># If the arg is say a string, we can specify varname:string to deref the str ptr.</span>
  <span class="nb">sudo </span>perf probe <span class="nt">-x</span> ./code <span class="nt">--add</span><span class="o">=</span><span class="s1">'add_with_sleep:0 sleep_us'</span>
  <span class="nb">sudo </span>perf probe <span class="nt">-x</span> ./code <span class="nt">--add</span><span class="o">=</span><span class="s1">'add_with_sleep%return'</span>

  <span class="nb">sudo </span>perf record <span class="nt">-e</span> probe_code:add_with_sleep <span class="nt">-e</span> probe_code:add_with_sleep__return ./code

  <span class="c"># This will generate a python script called perf-script.py</span>
  <span class="c"># Modify its entry and exit functions to print deltas between</span>
  <span class="c"># Entry and Exit timesteps</span>
  perf script <span class="nt">-g</span> python

  <span class="nb">sudo chown</span> <span class="si">$(</span><span class="nb">whoami</span><span class="si">)</span> perf.data
  perf script <span class="nt">-s</span> perf-script.py | less

  <span class="c">## Cleanup ##</span>

  <span class="c"># Should show two events</span>
  <span class="nb">sudo </span>perf probe <span class="nt">-l</span>
  <span class="nb">sudo </span>perf probe <span class="nt">-d</span> <span class="s1">'add_with_sleep'</span>
  <span class="nb">sudo </span>perf probe <span class="nt">-d</span> <span class="s1">'add_with_sleep%return'</span>
  <span class="c"># Should show zero events</span>
  <span class="nb">sudo </span>perf probe <span class="nt">-l</span>


<span class="o">}</span>

run
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">perf script -g python</code> will generate a file that looks something like this. Incorporate these changes into the script.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">start_arg</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">probe_code__add_with_sleep</span><span class="p">(</span><span class="n">event_name</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">common_cpu</span><span class="p">,</span> <span class="p">...):</span>
    <span class="k">global</span> <span class="n">start</span><span class="p">,</span> <span class="n">start_arg</span>
    <span class="n">start</span> <span class="o">=</span> <span class="p">(</span><span class="n">common_secs</span> <span class="o">*</span> <span class="mf">1e9</span><span class="p">)</span> <span class="o">+</span> <span class="n">common_nsecs</span>
    <span class="n">start_arg</span> <span class="o">=</span> <span class="n">sleep_us</span>

<span class="k">def</span> <span class="nf">probe_code__add_with_sleep__return</span><span class="p">(</span><span class="n">event_name</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">common_cpu</span> <span class="p">...):</span>
    <span class="k">global</span> <span class="n">start</span><span class="p">,</span> <span class="n">start_arg</span>
    <span class="n">end</span> <span class="o">=</span> <span class="p">(</span><span class="n">common_secs</span> <span class="o">*</span> <span class="mf">1e9</span><span class="p">)</span> <span class="o">+</span> <span class="n">common_nsecs</span>
    <span class="n">time_usec</span> <span class="o">=</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e3</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Sleep Arg: {:.0f} us, Sleep Time: {:.0f} us</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">start_arg</span><span class="p">,</span> <span class="n">time_usec</span><span class="p">))</span>
</code></pre></div></div> <h3 id="credits">CREDITS</h3> <ol> <li><a href="https://bristot.me/using-perf-probe-to-measure-execution-time-of-user-space-code-on-linux/">https://bristot.me/using-perf-probe-to-measure-execution-time-of-user-space-code-on-linux/</a></li> <li><a href="http://notes.secretsauce.net/notes/2019/12/16_c-probes-with-perf.html">http://notes.secretsauce.net/notes/2019/12/16_c-probes-with-perf.html</a></li> <li><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance</a></li> <li><a href="http://blog.vmsplice.net/2011/03/how-to-use-perf-probe.html">http://blog.vmsplice.net/2011/03/how-to-use-perf-probe.html</a></li> <li><a href="http://oliveryang.net/2016/07/linux-perf-tools-tips/">http://oliveryang.net/2016/07/linux-perf-tools-tips/</a></li> </ol>]]></content><author><name></name></author><category term="systems"/><category term="perf"/><summary type="html"><![CDATA[Using perf probes for dynamic instrumentation]]></summary></entry></feed>