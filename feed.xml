<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://anku94.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://anku94.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-12-15T19:41:51+00:00</updated><id>https://anku94.github.io/feed.xml</id><title type="html">Ankush Jain</title><subtitle>Ankush&apos;s personal website and blog on assorted systems topics </subtitle><entry><title type="html">Indian Union Budget - Expenditure Analysis</title><link href="https://anku94.github.io/blog/2023/govt-exp/" rel="alternate" type="text/html" title="Indian Union Budget - Expenditure Analysis"/><published>2023-11-11T04:35:31+00:00</published><updated>2023-11-11T04:35:31+00:00</updated><id>https://anku94.github.io/blog/2023/govt-exp</id><content type="html" xml:base="https://anku94.github.io/blog/2023/govt-exp/"><![CDATA[<p>Check <a href="https://anku94.github.io/dash/sankey">this</a> out! (Code <a href="https://github.com/anku94/dataviz">here</a>.)</p> <p>Government budgets are opaque. They utterly, absolutely, completely dwarf smaller social sector organizations trying to make anything better. They are also poorly understood.</p> <p>This is an attempt to demystify them - mostly for myself, maybe for others. This is also a WIP, and will (may?) get better over time. Understanding these datasets better helps us understand entrenched interest groups that have captured a disproportionate share of these sums (a typical pattern in democracies).</p> <p>Some quick notes on the process:</p> <ol> <li> <p>Indian govt. is organized as ministries, which are internally organized as departments. Some departments are directly managed by the PMO (I think?) and do not have a parent ministry as such. Each ministry creates multiple demands for grant, one for each department.</p> </li> <li> <p>I parsed a giant Excel sheet containing 100+ of these demands for grants, and organized them into a tree-like structure. This process was painful, and the python code that does this is a reflection of that. There are a couple of places where things get rounded off due to heuristics breaking down, but they should not cause massive issues.</p> </li> <li> <p>The data visualization in in a decent JS stack (NextJS, React, Typescript, Plotly.js …). Feel free to contribute!</p> </li> </ol>]]></content><author><name></name></author><category term="data"/><category term="js,"/><category term="goi"/><summary type="html"><![CDATA[Expenditure analysis and visualization of the Indian Govt. Union Budget for FY2023-24.]]></summary></entry><entry><title type="html">The Varied Flavors of Infiniband</title><link href="https://anku94.github.io/blog/2023/infiniband-flavors/" rel="alternate" type="text/html" title="The Varied Flavors of Infiniband"/><published>2023-09-11T19:05:42+00:00</published><updated>2023-09-11T19:05:42+00:00</updated><id>https://anku94.github.io/blog/2023/infiniband-flavors</id><content type="html" xml:base="https://anku94.github.io/blog/2023/infiniband-flavors/"><![CDATA[<p>This is an attempt to track and understand all the different “flavors” of Infiniband-like interfaces that are around, active, or relevant.</p> <p>Thinking of things like PSM, PSM2, OFI, Verbs, UCX etc. I doubt this particular post will have anything insightful — this is more of a placeholder for more insightful things in the future.</p> <h2 id="pre-historic-times-1995-2002">Pre-historic Times (1995-2002)</h2> <p>Most HPC clusters had proprietary networks, with their own <a href="https://agullo-teach.gitlabpages.inria.fr/school/school2019/slides/mpi.pdf">MPI providers</a>. Some weird-sounding names: MPICH-MX, MPICH-Elanlab.</p> <h2 id="ancient-times-1995-2002">Ancient Times (1995-2002)</h2> <p>InfiniBand: long awaited HPC network standard. Comes with OFED open-source networks stack, the <code class="language-plaintext highlighter-rouge">verbs</code> API. MPI implementations started using Verbs.</p> <h2 id="pre-modern-2005-2010-and-modern-2010-now-times">Pre-Modern (2005-2010) and Modern (2010-Now) Times</h2> <h3 id="performance-scaled-messaging">Performance-Scaled Messaging</h3> <p>Needs supposedly start outstripping the capabilities of the standards. PSM (Performance-Scaled Messaging) is introduced.</p> <h4 id="psm-owner-history">PSM Owner History</h4> <p>There used to be this company called QLogic. They developed network hardware, including “Infiniband”, in the pre-modern times.</p> <p>Their IB was compatible with the Verbs API, but was developed truly for this interface called PSM. They acquired PathScale (a compiler vendor, among other things maybe?) in 2006, and developed <em>InfiniPath</em>, also marketed as <em>TrueScale</em> — a network interface that was Infiniband-compatible but supported PSM for better performance.</p> <p>They were later sold to Intel. Their tech became the basis of a second-gen interconnect called <em>Omni-Path</em>. Omni-Path used an evolution of psm called psm2, which was not backward-compatible. The psm/Qlogic stuff was 40 Gbps, psm2/Omni-Path was 100 Gbps. As per <a href="https://www.nextplatform.com/2023/08/24/cornelis-unveils-ambitious-omni-path-interconnect-roadmap/">this</a>, Omni-Path also incorporated features from Gemini and Aries interconnects bought from Cray in 2012.</p> <p>Something happened at Intel around 2019 — they canceled the 200 Gbps variant of Omni-Path. In 2020, a company called Cornelis Networks was spun out to carry Omni-Path forward.</p> <p><a href="https://www.nextplatform.com/2021/07/09/a-third-dialect-of-infiniband-in-the-works-again/">Cornelis</a> still exists, and are continuing the development of Omni-Path-based products.</p> <h4 id="psm-technical-details">PSM Technical Details</h4> <p>This is more of questions and references.</p> <blockquote> <p>“The software infrastructure of InfiniBand, based on verbs, is really based on the original goals of InfiniBand, which was to replace PCI-X and Fibre Channel and maybe Ethernet,” Murphy tells The Next Platform. “Verbs were not structured at all for high performance computing. PathScale created Performance Scale Messaging, or PSM, which was totally independent of InfiniBand verbs and was a parallel transport layer specific focused on HPC. In the enterprise, when I am talking to 40 or 50 disk drives or 40 or 50 queue pairs, I can put that on my adapter’s cache and it works great. But in HPC, when I have a node with a hundred cores and a thousand nodes, this becomes a giant scalability problem we just cannot manage in the adapter’s cache. PSM could do this better, but even this was invented two decades ago and the world has continued to evolve.</p> </blockquote> <p>It seems one of the considerations for PSM was the NIC SRAM overhead of creating Verbs Queue Pairs. NIC SRAM is finite, and for all-to-all type communication patterns, the SRAM can not fit all the contexts. This <a href="https://www.usenix.org/system/files/conference/osdi16/osdi16-kalia.pdf">paper</a> also talks about prefering RDMA UDs over RCs. With RDMA UD, one queue pair can be used for multiple destinations, and the total number of QPs can be controlled. We don’t want CPU cores contending over UDs, so one QP/core is still desirable, but it scales with the number of cores, instead of the number of destinations, which is a lot more tractable for large clusters.</p> <p>One of the references also talks about dynamic congestion detection and rerouting borrowed from Aries and incorporated into Omni-Path. As per <a href="https://www.youtube.com/watch?v=E0uSl_gyZnI">this</a>: QLogic thought that the best way to provide scaling was to avoid hardware offload entirely, and have everything be done by building on efficient Host CPU-based primitives. Datacenter hardware trying to support TCP, as we know in hindsight, went in the opposite direction, and now we’re talking about DPUs and SmartNICs.</p> <h3 id="mellanox-and-nvidia">Mellanox and Nvidia</h3> <p>Something about Mellanox hacking Verbs, with “Accelerated Verbs”, MXM, UCX, RoCE, GPUDirect …</p> <h3 id="hpe-and-slingshot-and-ultraethernet">HPE and Slingshot and UltraEthernet</h3> <p>Similar stuff?</p> <h3 id="then-there-is-cxl">Then there is CXL</h3> <p>Phew.</p>]]></content><author><name></name></author><category term="systems"/><category term="networks"/><summary type="html"><![CDATA[Some description]]></summary></entry><entry><title type="html">Playing With Perf Probes - II</title><link href="https://anku94.github.io/blog/2023/more-perf/" rel="alternate" type="text/html" title="Playing With Perf Probes - II"/><published>2023-09-11T17:37:12+00:00</published><updated>2023-09-11T17:37:12+00:00</updated><id>https://anku94.github.io/blog/2023/more-perf</id><content type="html" xml:base="https://anku94.github.io/blog/2023/more-perf/"><![CDATA[<h3 id="problem-need-sudo-to-probe">Problem: Need Sudo To Probe</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>perf probe <span class="nt">-x</span> ./code <span class="nt">--add</span><span class="o">=</span><span class="s1">'add_with_sleep:0 sleep_us'</span>
</code></pre></div></div> <p>This will fail without <code class="language-plaintext highlighter-rouge">sudo</code> unless you’re root. A solid <a href="https://www.kdab.com/wp-content/uploads/stories/Linux_perf_for_Qt_developers.pdf">setup</a> that fixes most perf permissions issues:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">sudo </span>mount <span class="nt">-o</span> remount,mode<span class="o">=</span>755 /sys/kernel/debug
<span class="nb">sudo </span>mount <span class="nt">-o</span> remount,mode<span class="o">=</span>755 /sys/kernel/debug/tracing
<span class="nb">echo </span>0 | <span class="nb">sudo tee</span> /proc/sys/kernel/kptr_restrict
<span class="nb">echo</span> <span class="nt">-1</span> | <span class="nb">sudo tee</span> /proc/sys/kernel/perf_event_paranoid
<span class="nb">sudo chown </span>root:tracing /sys/kernel/debug/tracing/uprobe_events
<span class="nb">sudo chmod </span>g+rw /sys/kernel/debug/tracing/uprobe_events

</code></pre></div></div> <h3 id="probing-internal-library-functions">Probing Internal Library Functions</h3> <p>You’re going through the source code of your library, and there’s a specific internal function you want to profile. But it’s not listed in <code class="language-plaintext highlighter-rouge">perf probe -x exec -F</code>. It probably isn’t listed in <code class="language-plaintext highlighter-rouge">nm -a exec</code> either. If your functions are using this:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="n">__inline__</span> <span class="n">FN</span> <span class="nf">__attribute__</span><span class="p">((</span><span class="n">always_inline</span><span class="p">));</span>
</code></pre></div></div> <p>There’s no way they’re making it to the compiled output. This must be deleted. With <code class="language-plaintext highlighter-rouge">__inline__</code> and <code class="language-plaintext highlighter-rouge">inline</code>, things vary. There are two things I needed to get gcc to preserve my symbols up to the final <code class="language-plaintext highlighter-rouge">.so</code> object:</p> <ol> <li>Remove <code class="language-plaintext highlighter-rouge">always_inline</code> from code</li> <li>Add <code class="language-plaintext highlighter-rouge">-fvisibility=default</code> to my compiler flags</li> <li>Add <code class="language-plaintext highlighter-rouge">-fno-inline</code> to counter the anti-debugging forces channeled by <code class="language-plaintext highlighter-rouge">-O3</code></li> </ol> <p>More references:</p> <ul> <li><a href="https://minervadb.xyz/wp-content/uploads/2020/12/Dynamic-Tracing-for-Finding-and-Solving-MySQL-Performance-Problems-on-Linux-MinervaDB-Database-Platforms-Virtual-Conference-2020.pdf">MinervaDB</a></li> <li><a href="https://www.spinics.net/lists/linux-perf-users/msg02465.html">MailingList</a></li> </ul>]]></content><author><name></name></author><category term="systems"/><category term="perf"/><summary type="html"><![CDATA[Using perf probes for dynamic instrumentation]]></summary></entry><entry><title type="html">Playing With Perf Probes</title><link href="https://anku94.github.io/blog/2023/playing-with-perf-probes/" rel="alternate" type="text/html" title="Playing With Perf Probes"/><published>2023-09-09T00:18:33+00:00</published><updated>2023-09-09T00:18:33+00:00</updated><id>https://anku94.github.io/blog/2023/playing-with-perf-probes</id><content type="html" xml:base="https://anku94.github.io/blog/2023/playing-with-perf-probes/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Playing With Perf Probes</title><link href="https://anku94.github.io/blog/2023/perf-probes/" rel="alternate" type="text/html" title="Playing With Perf Probes"/><published>2023-09-08T19:56:00+00:00</published><updated>2023-09-08T19:56:00+00:00</updated><id>https://anku94.github.io/blog/2023/perf-probes</id><content type="html" xml:base="https://anku94.github.io/blog/2023/perf-probes/"><![CDATA[<p>This post demonstrates the power of perf probes, using the following example C code. Let’s say we’d like to verify that usleep actually sleeps for the claimed amount of time. This is the output we can get.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Sleep Arg: 0 us, Sleep Time: 92 us
Sleep Arg: 100 us, Sleep Time: 167 us
Sleep Arg: 200 us, Sleep Time: 262 us
Sleep Arg: 300 us, Sleep Time: 370 us
Sleep Arg: 400 us, Sleep Time: 468 us
Sleep Arg: 500 us, Sleep Time: 584 us
Sleep Arg: 600 us, Sleep Time: 684 us
Sleep Arg: 700 us, Sleep Time: 784 us
Sleep Arg: 800 us, Sleep Time: 885 us
</code></pre></div></div> <p>Code for this exercise.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">add_with_sleep</span><span class="p">(</span><span class="kt">int</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="n">sleep_us</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">usleep</span><span class="p">(</span><span class="n">sleep_us</span><span class="p">);</span>
  <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">;</span>

<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">ret</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">ret</span> <span class="o">+=</span> <span class="n">add_with_sleep</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="o">*</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">100</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"I: %d, Ret: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">ret</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>Series of commands. You can run them line by line.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

setup<span class="o">()</span> <span class="o">{</span>
  <span class="nb">echo</span> <span class="nt">-1</span> | <span class="nb">sudo tee</span> /proc/sys/kernel/perf_event_paranoid
<span class="o">}</span>

run<span class="o">()</span> <span class="o">{</span>
  gcc <span class="nt">-g</span> <span class="nt">-o</span> code code.c
  ./code

  <span class="nb">alias </span><span class="nv">perf</span><span class="o">=</span>~/.local/bin/perf

  <span class="c"># -g enables call graph</span>
  perf record <span class="nt">-g</span> ./code

  <span class="c"># DWARF enables better stack unwinding</span>
  perf record <span class="nt">-g</span> <span class="nt">--call-graph</span><span class="o">=</span>dwarf ./code
  perf report <span class="nt">--stdio</span>

  <span class="c"># Show probe-able functions in binary</span>
  perf probe <span class="nt">-x</span> ./code <span class="nt">-F</span>

  <span class="c"># Show probe-able function lines in binary</span>
  perf probe <span class="nt">-x</span> ./code <span class="nt">-L</span> add_with_sleep

  <span class="c"># Show probe-able function lines in binary</span>
  perf probe <span class="nt">-x</span> ./code <span class="nt">-L</span> add_with_sleep:2

  <span class="c"># Show available variables at some point</span>
  perf probe <span class="nt">-x</span> ./code <span class="nt">-V</span> add_with_sleep:2

  <span class="c"># Add probes for function entry and exit. At entry, we also capture the arg.</span>
  <span class="c"># If the arg is say a string, we can specify varname:string to deref the str ptr.</span>
  <span class="nb">sudo </span>perf probe <span class="nt">-x</span> ./code <span class="nt">--add</span><span class="o">=</span><span class="s1">'add_with_sleep:0 sleep_us'</span>
  <span class="nb">sudo </span>perf probe <span class="nt">-x</span> ./code <span class="nt">--add</span><span class="o">=</span><span class="s1">'add_with_sleep%return'</span>

  <span class="nb">sudo </span>perf record <span class="nt">-e</span> probe_code:add_with_sleep <span class="nt">-e</span> probe_code:add_with_sleep__return ./code

  <span class="c"># This will generate a python script called perf-script.py</span>
  <span class="c"># Modify its entry and exit functions to print deltas between</span>
  <span class="c"># Entry and Exit timesteps</span>
  perf script <span class="nt">-g</span> python

  <span class="nb">sudo chown</span> <span class="si">$(</span><span class="nb">whoami</span><span class="si">)</span> perf.data
  perf script <span class="nt">-s</span> perf-script.py | less

  <span class="c">## Cleanup ##</span>

  <span class="c"># Should show two events</span>
  <span class="nb">sudo </span>perf probe <span class="nt">-l</span>
  <span class="nb">sudo </span>perf probe <span class="nt">-d</span> <span class="s1">'add_with_sleep'</span>
  <span class="nb">sudo </span>perf probe <span class="nt">-d</span> <span class="s1">'add_with_sleep%return'</span>
  <span class="c"># Should show zero events</span>
  <span class="nb">sudo </span>perf probe <span class="nt">-l</span>


<span class="o">}</span>

run
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">perf script -g python</code> will generate a file that looks something like this. Incorporate these changes into the script.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">start_arg</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">probe_code__add_with_sleep</span><span class="p">(</span><span class="n">event_name</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">common_cpu</span><span class="p">,</span> <span class="p">...):</span>
    <span class="k">global</span> <span class="n">start</span><span class="p">,</span> <span class="n">start_arg</span>
    <span class="n">start</span> <span class="o">=</span> <span class="p">(</span><span class="n">common_secs</span> <span class="o">*</span> <span class="mf">1e9</span><span class="p">)</span> <span class="o">+</span> <span class="n">common_nsecs</span>
    <span class="n">start_arg</span> <span class="o">=</span> <span class="n">sleep_us</span>

<span class="k">def</span> <span class="nf">probe_code__add_with_sleep__return</span><span class="p">(</span><span class="n">event_name</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">common_cpu</span> <span class="p">...):</span>
    <span class="k">global</span> <span class="n">start</span><span class="p">,</span> <span class="n">start_arg</span>
    <span class="n">end</span> <span class="o">=</span> <span class="p">(</span><span class="n">common_secs</span> <span class="o">*</span> <span class="mf">1e9</span><span class="p">)</span> <span class="o">+</span> <span class="n">common_nsecs</span>
    <span class="n">time_usec</span> <span class="o">=</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e3</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Sleep Arg: {:.0f} us, Sleep Time: {:.0f} us</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">start_arg</span><span class="p">,</span> <span class="n">time_usec</span><span class="p">))</span>
</code></pre></div></div> <h3 id="credits">CREDITS</h3> <ol> <li><a href="https://bristot.me/using-perf-probe-to-measure-execution-time-of-user-space-code-on-linux/">https://bristot.me/using-perf-probe-to-measure-execution-time-of-user-space-code-on-linux/</a></li> <li><a href="http://notes.secretsauce.net/notes/2019/12/16_c-probes-with-perf.html">http://notes.secretsauce.net/notes/2019/12/16_c-probes-with-perf.html</a></li> <li><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance</a></li> <li><a href="http://blog.vmsplice.net/2011/03/how-to-use-perf-probe.html">http://blog.vmsplice.net/2011/03/how-to-use-perf-probe.html</a></li> <li><a href="http://oliveryang.net/2016/07/linux-perf-tools-tips/">http://oliveryang.net/2016/07/linux-perf-tools-tips/</a></li> </ol>]]></content><author><name></name></author><category term="systems"/><category term="perf"/><summary type="html"><![CDATA[Using perf probes for dynamic instrumentation]]></summary></entry><entry><title type="html">Profiling MPI with Perf</title><link href="https://anku94.github.io/blog/2023/profiling-mpi-with-perf/" rel="alternate" type="text/html" title="Profiling MPI with Perf"/><published>2023-09-05T00:29:25+00:00</published><updated>2023-09-05T00:29:25+00:00</updated><id>https://anku94.github.io/blog/2023/profiling-mpi-with-perf</id><content type="html" xml:base="https://anku94.github.io/blog/2023/profiling-mpi-with-perf/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Notes on MPI+X vs Chapel</title><link href="https://anku94.github.io/blog/2023/notes-on-mpix-vs-chapel/" rel="alternate" type="text/html" title="Notes on MPI+X vs Chapel"/><published>2023-08-31T00:57:36+00:00</published><updated>2023-08-31T00:57:36+00:00</updated><id>https://anku94.github.io/blog/2023/notes-on-mpix-vs-chapel</id><content type="html" xml:base="https://anku94.github.io/blog/2023/notes-on-mpix-vs-chapel/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">On MMIO, DMA, and PCIe 3.0</title><link href="https://anku94.github.io/blog/2023/on-mmio-dma-and-pcie-30/" rel="alternate" type="text/html" title="On MMIO, DMA, and PCIe 3.0"/><published>2023-07-13T03:42:32+00:00</published><updated>2023-07-13T03:42:32+00:00</updated><id>https://anku94.github.io/blog/2023/on-mmio-dma-and-pcie-30</id><content type="html" xml:base="https://anku94.github.io/blog/2023/on-mmio-dma-and-pcie-30/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">On Taylor Swift, Tickets, and Scale</title><link href="https://anku94.github.io/blog/2022/on-taylor-swift-tickets-and-scale/" rel="alternate" type="text/html" title="On Taylor Swift, Tickets, and Scale"/><published>2022-11-18T18:55:38+00:00</published><updated>2022-11-18T18:55:38+00:00</updated><id>https://anku94.github.io/blog/2022/on-taylor-swift-tickets-and-scale</id><content type="html" xml:base="https://anku94.github.io/blog/2022/on-taylor-swift-tickets-and-scale/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">notes on linux graphics</title><link href="https://anku94.github.io/blog/2022/notes-on-linux-graphics/" rel="alternate" type="text/html" title="notes on linux graphics"/><published>2022-08-27T03:28:20+00:00</published><updated>2022-08-27T03:28:20+00:00</updated><id>https://anku94.github.io/blog/2022/notes-on-linux-graphics</id><content type="html" xml:base="https://anku94.github.io/blog/2022/notes-on-linux-graphics/"><![CDATA[]]></content><author><name></name></author></entry></feed>