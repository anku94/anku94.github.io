<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://ankushja.in/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ankushja.in/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-23T06:08:09+00:00</updated><id>https://ankushja.in/feed.xml</id><title type="html">Ankush Jain</title><subtitle>Personal website and blog of Ankush Jain, PhD Student at CMU PDL. Topics include systems, storage, networks, HPC etc. </subtitle><entry><title type="html">QoS in Infiniband</title><link href="https://ankushja.in/blog/2025/ibqos/" rel="alternate" type="text/html" title="QoS in Infiniband"/><published>2025-09-20T15:31:23+00:00</published><updated>2025-09-20T15:31:23+00:00</updated><id>https://ankushja.in/blog/2025/ibqos</id><content type="html" xml:base="https://ankushja.in/blog/2025/ibqos/"><![CDATA[<p>These are some sloppy notes on my attempts to figure out how to configure QoS in infiniband-based stacks. They are in rough shape, my conclusion so far seems to be that libfabric hard sets a service level, but doesn’t allow for it to be configurable. I don’t know if it’s possible to call <code class="language-plaintext highlighter-rouge">ibv_modify_qp</code> or something to do so after verbs has intialized.</p> <h2 id="basic-ib-concepts">Basic IB Concepts</h2> <h3 id="simple-case-one-subnet">Simple Case: One Subnet</h3> <ul> <li>Subnet Manager (<code class="language-plaintext highlighter-rouge">SM</code>): manages the subnet (thx). Like DHCP + ARP + more things.</li> <li><code class="language-plaintext highlighter-rouge">lid</code>: like IP address, assigned by subnet manager, you can ping it, send to it, whatever.</li> </ul> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">$</span> <span class="n">sudo</span> <span class="n">ibstat</span>
<span class="no">CA</span> <span class="err">'</span><span class="n">qib0</span><span class="err">'</span>
		<span class="o">...</span>
        <span class="nc">Port</span> <span class="mi">1</span><span class="o">:</span>
                <span class="nl">State:</span> <span class="nc">Active</span>
                <span class="nc">Physical</span> <span class="nl">state:</span> <span class="nc">LinkUp</span>
                <span class="nc">Base</span> <span class="nl">lid:</span> <span class="mi">475</span>
                <span class="no">SM</span> <span class="nl">lid:</span> <span class="mi">10</span>
				<span class="o">...</span>
</code></pre></div></div> <p>SM is lid=10, and this node has a HCA (NIC) with lid=0.</p> <h3 id="complex-case-multiple-subnets">Complex Case: Multiple Subnets</h3> <p>Here routing comes into the picture. Won’t go into details, but simple/sloppy version:</p> <ul> <li><code class="language-plaintext highlighter-rouge">guid: u64</code>: like MAC address, unique per device.</li> <li><code class="language-plaintext highlighter-rouge">gid: u128</code>: globally unique ID, <code class="language-plaintext highlighter-rouge">sm_id: u64</code> + <code class="language-plaintext highlighter-rouge">guid: u64</code></li> </ul> <p>Switches maintain routes indexed by <code class="language-plaintext highlighter-rouge">sm_id</code>, hosts send packets to <code class="language-plaintext highlighter-rouge">gid</code>s, switches look up the relevant destination and forward. Not relevant to us going forward.</p> <h3 id="miscellaneous">Miscellaneous</h3> <ul> <li>Service Level (<code class="language-plaintext highlighter-rouge">SL</code>): a 4-bit priority carried by a packet</li> <li>Virtual Lane (<code class="language-plaintext highlighter-rouge">VL</code>): hardware-level egress lanes over a link, these actually provide QoS Isolation</li> <li><code class="language-plaintext highlighter-rouge">SL2VL</code>: a table mapping SLs to VLs. SLs confer QoS properties only if they are mapped to separate VLs, and as per specific configuration in <code class="language-plaintext highlighter-rouge">VLArb</code> (the VL arbitration tables)</li> <li>Subnet Management Packet (<code class="language-plaintext highlighter-rouge">SMP</code>): used by SM to configure and query fabric components (ports and switches)</li> <li>Management Datagram (<code class="language-plaintext highlighter-rouge">MAD</code>): management message format, UMAD is the linux interface to send MAD packets</li> <li>Subnet Administrator (<code class="language-plaintext highlighter-rouge">SA</code>): a management service that answers queries (part of the Subnet Manager?)</li> <li>OpenSM: an open-source software-based subnet manager (like <code class="language-plaintext highlighter-rouge">dnsmasq</code> for DHCP). Fabrics may have proprietary ones.</li> <li><code class="language-plaintext highlighter-rouge">VL15</code>: a dedicated VL for SMP traffic (<code class="language-plaintext highlighter-rouge">QP0</code>: a special queue pair dedicated for it?)</li> </ul> <h2 id="how-many-vls-do-i-have">How Many VLs Do I Have?</h2> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">$</span> <span class="n">smpquery</span> <span class="n">portinfo</span> <span class="o">&lt;</span><span class="n">lid</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">portnum</span><span class="o">&gt;</span>
<span class="nl">ibwarn:</span> <span class="o">[</span><span class="mi">1006476</span><span class="o">]</span> <span class="nl">mad_rpc_open_port:</span> <span class="n">can</span><span class="err">'</span><span class="n">t</span> <span class="n">open</span> <span class="no">UMAD</span> <span class="nf">port</span> <span class="o">((</span><span class="kc">null</span><span class="o">):</span><span class="mi">0</span><span class="o">)</span>
<span class="nl">smpquery:</span> <span class="nl">iberror:</span> <span class="nl">failed:</span> <span class="nc">Failed</span> <span class="n">to</span> <span class="n">open</span> <span class="err">'</span><span class="o">(</span><span class="kc">null</span><span class="o">)</span><span class="err">'</span> <span class="n">port</span> <span class="sc">'0'</span>

<span class="err">$</span> <span class="n">sudo</span> <span class="n">smpquery</span> <span class="n">portinfo</span> <span class="o">&lt;</span><span class="n">lid</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">portnum</span><span class="o">&gt;</span>
<span class="nl">CapMask:</span><span class="o">.........................</span><span class="mh">0x7610868</span>
                                <span class="nc">IsTrapSupported</span>
                                <span class="nc">IsAutomaticMigrationSupported</span>
                                <span class="nc">IsSLMappingSupported</span>
                                <span class="nc">IsSystemImageGUIDsupported</span>
                                <span class="nc">IsCommunicatonManagementSupported</span>
                                <span class="nc">IsDRNoticeSupported</span>
                                <span class="nc">IsCapabilityMaskNoticeSupported</span>
                                <span class="nc">IsLinkRoundTripLatencySupported</span>
                                <span class="nc">IsClientRegistrationSupported</span>
                                <span class="nc">IsOtherLocalChangesNoticeSupported</span>
<span class="nl">VLCap:</span><span class="o">...........................</span><span class="na">VL0</span><span class="o">-</span><span class="mi">1</span>
<span class="nl">VLHighLimit:</span><span class="o">.....................</span><span class="mi">0</span>
<span class="nl">VLArbHighCap:</span><span class="o">....................</span><span class="mi">16</span>
<span class="nl">VLArbLowCap:</span><span class="o">.....................</span><span class="mi">16</span>
<span class="nl">VLStallCount:</span><span class="o">....................</span><span class="mi">0</span>
<span class="nl">OperVLs:</span><span class="o">.........................</span><span class="na">VL0</span>
</code></pre></div></div> <p>Takeaways:</p> <ol> <li>SLs/VLs are supported (<code class="language-plaintext highlighter-rouge">CapMask</code> has <code class="language-plaintext highlighter-rouge">IsSLMappingSupported</code>).</li> <li><code class="language-plaintext highlighter-rouge">VLCap</code> suggests that two virtual lanes are possible (<code class="language-plaintext highlighter-rouge">VL0</code> and <code class="language-plaintext highlighter-rouge">VL1</code>)</li> <li><code class="language-plaintext highlighter-rouge">OperVLs</code> suggests that only one VL is configured, operational, active, <code class="language-plaintext highlighter-rouge">VL1</code> is not configured.</li> </ol> <h2 id="what-is-the-configured-qos-state">What Is The Configured QoS State?</h2> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">$</span> <span class="n">sudo</span> <span class="n">smpquery</span> <span class="n">sl2vl</span> <span class="mi">475</span> <span class="mi">1</span>
<span class="err">#</span> <span class="no">SL2VL</span> <span class="nl">table:</span> <span class="nc">Lid</span> <span class="mi">475</span>
<span class="err">#</span>                 <span class="nl">SL:</span> <span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">1</span><span class="o">|</span> <span class="mi">2</span><span class="o">|</span> <span class="mi">3</span><span class="o">|</span> <span class="mi">4</span><span class="o">|</span> <span class="mi">5</span><span class="o">|</span> <span class="mi">6</span><span class="o">|</span> <span class="mi">7</span><span class="o">|</span> <span class="mi">8</span><span class="o">|</span> <span class="mi">9</span><span class="o">|</span><span class="mi">10</span><span class="o">|</span><span class="mi">11</span><span class="o">|</span><span class="mi">12</span><span class="o">|</span><span class="mi">13</span><span class="o">|</span><span class="mi">14</span><span class="o">|</span><span class="mi">15</span><span class="o">|</span>
<span class="nl">ports:</span> <span class="n">in</span>  <span class="mi">0</span><span class="o">,</span> <span class="n">out</span>  <span class="mi">0</span><span class="o">:</span> <span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span> <span class="mi">0</span><span class="o">|</span>

<span class="err">$</span> <span class="n">sudo</span> <span class="n">smpquery</span> <span class="n">vlarb</span> <span class="mi">475</span> <span class="mi">1</span>
<span class="err">#</span> <span class="nc">VLArbitration</span> <span class="nl">tables:</span> <span class="nc">Lid</span> <span class="mi">475</span> <span class="n">port</span> <span class="mi">1</span> <span class="nc">LowCap</span> <span class="mi">16</span> <span class="nc">HighCap</span> <span class="mi">16</span>
<span class="err">#</span> <span class="nc">Low</span> <span class="n">priority</span> <span class="no">VL</span> <span class="nc">Arbitration</span> <span class="nl">Table:</span>
<span class="no">VL</span>    <span class="o">:</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span>
<span class="nl">WEIGHT:</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span>
<span class="err">#</span> <span class="nc">High</span> <span class="n">priority</span> <span class="no">VL</span> <span class="nc">Arbitration</span> <span class="nl">Table:</span>
<span class="no">VL</span>    <span class="o">:</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span>
<span class="nl">WEIGHT:</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span><span class="mh">0x0</span> <span class="o">|</span>
</code></pre></div></div> <p>Takeaways:</p> <ol> <li><code class="language-plaintext highlighter-rouge">sl2vl</code> says that we have 16 SLs, but all are mapped to VL0, so no QoS.</li> <li><code class="language-plaintext highlighter-rouge">vlarb</code> is all <code class="language-plaintext highlighter-rouge">VL0</code>. There are two levels of priority classes. First level is <code class="language-plaintext highlighter-rouge">vlarb_high</code> and <code class="language-plaintext highlighter-rouge">vlarb_low</code>. Second level is intra-vlarb, between <code class="language-plaintext highlighter-rouge">(sl, weight)</code> entries. The relative weight of vlarb-high/low is in <code class="language-plaintext highlighter-rouge">VLHighLimit</code>.</li> </ol> <h2 id="configuring-qos-in-opensm">Configuring QoS in OpenSM</h2> <p>You edit <code class="language-plaintext highlighter-rouge">/etc/opensm/opensm.conf</code> with something like this:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp"># enable QoS
</span><span class="n">qos</span> <span class="n">TRUE</span>

<span class="cp"># all prefixes are qos_
# specific sub-prefixes: qos_ca_, qos_rtr_, qos_sw0_, qos_swe_
# (for specific config for CAs, routers, switch port 0's, and switches)
</span>
<span class="n">qos_max_vls</span> <span class="mi">2</span>
<span class="cp"># send this many from high-priority first (255 ~ infinite priority)
</span><span class="n">qos_high_limit</span> <span class="mi">255</span>
<span class="cp"># intra-high priority
</span><span class="n">qos_vlarb_high</span> <span class="mi">1</span><span class="o">:</span><span class="mi">192</span><span class="p">,</span> <span class="mi">2</span><span class="o">:</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="o">:</span><span class="mi">64</span>
<span class="n">qos_vlarb_low</span> <span class="mi">0</span><span class="o">:</span><span class="mi">64</span>
<span class="cp"># SLs [0, 4) are VL0, [4, 8) are VL1
</span><span class="n">qos_sl2vl</span> <span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span>
</code></pre></div></div> <p>The policy for relative weights between the high-priority table and the low-priority table is not clear to me. That is, what exactly does <code class="language-plaintext highlighter-rouge">qos_vlarb_high</code> do.</p> <p>Note: <a href="https://www.mail-archive.com/lustre-discuss@lists.lustre.org/msg04092.html">https://www.mail-archive.com/lustre-discuss@lists.lustre.org/msg04092.html</a> is a good description of the <code class="language-plaintext highlighter-rouge">qos_high_limit</code>. It seems to me that the high class preempts the low class up to the high limit (preempts not mid-packet, but otherwise).</p> <p>There’s also ULP-based QoS I think (ULP: Upper Layer Protocol). Can maybe target service IDs for MPI, Lustre etc.</p> <h2 id="service-ids">Service IDs</h2> <ul> <li>Lustre etc. can register a Service Record with SA, containing (Service ID, server LID, service name)</li> <li>RDMA-CM (Connection Manager) is involved somehow</li> <li>RDMA-CM divides the SID space into port spaces. <code class="language-plaintext highlighter-rouge">RDMA_PS_TCP</code> is a 16-bit namespace.</li> </ul> <p>So SID can be <code class="language-plaintext highlighter-rouge">RDMA_PS_TCP &lt;&lt; 16 | service_port</code>, or <code class="language-plaintext highlighter-rouge">RDMA_PS_IB &lt;&lt; 16 | qpn</code>.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">$</span> <span class="n">sudo</span> <span class="n">saquery</span> <span class="o">-</span><span class="n">S</span>
<span class="o">&lt;</span><span class="n">nothing</span><span class="o">&gt;</span>
<span class="err">$</span> <span class="n">sudo</span> <span class="n">saquery</span>
<span class="o">&lt;</span><span class="n">bunch</span> <span class="n">of</span> <span class="n">node</span> <span class="n">records</span><span class="o">&gt;</span>
<span class="cp"># On Lustre root
</span><span class="err">$</span> <span class="n">cat</span> <span class="o">/</span><span class="n">sys</span><span class="o">/</span><span class="n">module</span><span class="o">/</span><span class="n">ko2iblnd</span><span class="o">/</span><span class="n">parameters</span><span class="o">/</span><span class="n">service</span>
<span class="mi">987</span>
</code></pre></div></div> <p>So it seems that Lustre’s SID is <code class="language-plaintext highlighter-rouge">RDMA_PS_TCP &lt;&lt; 16 | 987</code></p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">$</span> <span class="n">rdma</span> <span class="n">resource</span> <span class="n">show</span> <span class="n">cm_id</span> <span class="o">|</span> <span class="n">grep</span> <span class="n">LISTEN</span>
<span class="n">link</span> <span class="n">qib0</span><span class="o">/</span><span class="mi">1</span> <span class="n">cm</span><span class="o">-</span><span class="n">idn</span> <span class="mi">0</span> <span class="n">state</span> <span class="n">LISTEN</span> <span class="n">ps</span> <span class="n">TCP</span> <span class="n">comm</span> <span class="p">[</span><span class="n">ko2iblnd</span><span class="p">]</span> <span class="n">src</span><span class="o">-</span><span class="n">addr</span> <span class="mi">10</span><span class="p">.</span><span class="mi">94</span><span class="p">.</span><span class="n">xxx</span><span class="p">.</span><span class="n">yyy</span><span class="o">:</span><span class="mi">987</span> <span class="n">dst</span><span class="o">-</span><span class="n">addr</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">:</span><span class="mi">0</span>
<span class="cp"># P=987, 0x106 is the `RDMA_PS_TCP`
</span><span class="err">$</span> <span class="n">P</span><span class="o">=</span><span class="mi">987</span><span class="p">;</span> <span class="n">printf</span> <span class="err">'</span><span class="mi">0</span><span class="n">x</span><span class="o">%</span><span class="mo">016</span><span class="n">x</span><span class="err">\</span><span class="n">n</span><span class="err">'</span> <span class="err">$</span><span class="p">((</span> <span class="p">(</span><span class="mh">0x106</span><span class="o">&lt;&lt;</span><span class="mi">16</span><span class="p">)</span> <span class="o">|</span> <span class="n">P</span> <span class="p">))</span>
<span class="mh">0x00000000010603db</span> <span class="err">#</span> <span class="n">Service</span> <span class="n">ID</span> <span class="k">for</span> <span class="n">Lustre</span>
</code></pre></div></div> <p>This also shows 987 for Lustre. This maps Lustre to SL1.</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp"># /var/cache/opensm/qos-policy.conf
</span>
<span class="n">qos</span><span class="o">-</span><span class="n">ulps</span>
<span class="err"> </span> <span class="k">default</span> <span class="o">:</span> <span class="mi">0</span>
<span class="err"> </span> <span class="n">any</span><span class="p">,</span> <span class="n">service</span><span class="o">-</span><span class="n">id</span> <span class="mh">0x00000000010603DB</span> <span class="o">:</span> <span class="mi">1</span>
<span class="n">end</span><span class="o">-</span><span class="n">qos</span><span class="o">-</span><span class="n">ulps</span>
</code></pre></div></div> <h3 id="qos-in-psm">QoS in PSM</h3> <ul> <li>Use env variable <code class="language-plaintext highlighter-rouge">IPATH_SL</code>.</li> </ul> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">psmi_getenv</span><span class="p">(</span><span class="s">"IPATH_SL"</span><span class="p">,</span> <span class="s">"IB outging ServiceLevel number (default 0)"</span><span class="p">,</span>
		<span class="n">PSMI_ENVVAR_LEVEL_USER</span><span class="p">,</span> <span class="n">PSMI_ENVVAR_TYPE_LONG</span><span class="p">,</span>
		<span class="p">(</span><span class="k">union</span> <span class="n">psmi_envvar_val</span><span class="p">)</span> <span class="n">PSMI_SL_DEFAULT</span><span class="p">,</span>
		<span class="o">&amp;</span><span class="n">env_sl</span><span class="p">))</span> <span class="p">{</span>
<span class="n">opts</span><span class="p">.</span><span class="n">outsl</span> <span class="o">=</span> <span class="n">env_sl</span><span class="p">.</span><span class="n">e_long</span><span class="p">;</span>
<span class="p">}</span>

<span class="c1">// This seems to be older code for PSM v1.07 to 1.10. Head is 1.16</span>
<span class="c1">// No need to set VL in head, will use </span>
<span class="cp">#if (PSM_VERNO &gt;= 0x0107) &amp;&amp; (PSM_VERNO &lt;= 0x010a)
</span><span class="p">{</span>
  <span class="k">union</span> <span class="n">psmi_envvar_val</span> <span class="n">env_vl</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">psmi_getenv</span><span class="p">(</span><span class="s">"IPATH_VL"</span><span class="p">,</span> <span class="s">"IB outging VirtualLane (default 0)"</span><span class="p">,</span>
		   <span class="n">PSMI_ENVVAR_LEVEL_USER</span><span class="p">,</span> <span class="n">PSMI_ENVVAR_TYPE_LONG</span><span class="p">,</span>
		   <span class="p">(</span><span class="k">union</span> <span class="n">psmi_envvar_val</span><span class="p">)</span><span class="mi">0</span><span class="p">,</span>
		   <span class="o">&amp;</span><span class="n">env_vl</span><span class="p">))</span> <span class="p">{</span>
<span class="n">opts</span><span class="p">.</span><span class="n">outvl</span> <span class="o">=</span> <span class="n">env_vl</span><span class="p">.</span><span class="n">e_long</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>
<span class="cp">#endif
</span>
</code></pre></div></div> <h3 id="qos-in-libfabricmercury">QoS in libfabric/Mercury</h3> <p>Traffic classes are in <code class="language-plaintext highlighter-rouge">fi_tx_attr-&gt;tclass (u32)</code>: <a href="https://ofiwg.github.io/libfabric/main/man/fi_endpoint.3.html">https://ofiwg.github.io/libfabric/main/man/fi_endpoint.3.html</a></p> <p>Mercury (since v2.4):</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hg_opts</span><span class="p">.</span><span class="n">na_init_info</span><span class="p">.</span><span class="n">traffic_class</span> <span class="o">=</span> <span class="p">(</span><span class="kt">uint8_t</span><span class="p">)(</span><span class="n">desired_sl</span> <span class="o">&lt;&lt;</span> <span class="mi">5</span><span class="p">);</span> <span class="c1">// SL -&gt; tclass</span>
</code></pre></div></div> <p>Maybe something here: <a href="https://docs.nvidia.com/doca/sdk/rdma%2Bover%2Bconverged%2Bethernet/index.html">https://docs.nvidia.com/doca/sdk/rdma%2Bover%2Bconverged%2Bethernet/index.html</a></p> <p>Things I’ve established so far:</p> <ol> <li>I’m interested in <code class="language-plaintext highlighter-rouge">verbs; ofi_rxm</code></li> <li><code class="language-plaintext highlighter-rouge">ofi_rxm</code> just passes <code class="language-plaintext highlighter-rouge">tclass</code> to the core provider (which is verbs)</li> <li>I can’t find out what verbs does with it. It seems to use both <code class="language-plaintext highlighter-rouge">ibv</code> APIs and <code class="language-plaintext highlighter-rouge">rdma-cm</code> APIs. Looks like I may be looking for <code class="language-plaintext highlighter-rouge">rdma_set_option(RDMA_OPTION_ID_TOS)</code>. But nothing calls that.</li> </ol> <h3 id="update-20250923">Update: 20250923</h3> <p>QoS in libfabric verbs provider: The verbs provider implements QoS through InfiniBand’s native Service Level (SL) mechanism. However, unlike other libfabric providers (e.g., CXI), verbs has no traffic class (tclass) support. The SL is essentially fixed at endpoint creation time and cannot be modified at runtime without recreating the address handle, which would require modifying the libfabric source code.</p> <ul> <li>SL set in AH: <code class="language-plaintext highlighter-rouge">prov/verbs/src/verbs_dgram_av.c:65</code> - where <code class="language-plaintext highlighter-rouge">ah_attr.sl</code> gets the SL value during address handle creation</li> <li>SL source: <code class="language-plaintext highlighter-rouge">prov/verbs/src/verbs_ep.c:840</code> - where endpoint gets SL from subnet manager default <code class="language-plaintext highlighter-rouge">port_attr.sm_sl</code></li> <li>No tclass support: <code class="language-plaintext highlighter-rouge">prov/verbs/src/verbs_ep.c:358</code> - <code class="language-plaintext highlighter-rouge">vrb_ep_setopt()</code> function only handles CUDA options, no tclass</li> <li>Compare CXI: <code class="language-plaintext highlighter-rouge">prov/cxi/src/cxip_ep.c:1148</code> - shows how other providers handle <code class="language-plaintext highlighter-rouge">FI_OPT_CXI_SET_TCLASS</code></li> <li>Traffic class constants: <code class="language-plaintext highlighter-rouge">include/rdma/fabric.h:357</code> - the <code class="language-plaintext highlighter-rouge">FI_TC_*</code> enums that verbs doesn’t use</li> </ul> <h2 id="also-read">Also Read</h2> <ul> <li><a href="https://hpcadvisorycouncil.atlassian.net/wiki/spaces/HPCWORKS/pages/1178075141/Understanding+Basic+InfiniBand+QoS">https://hpcadvisorycouncil.atlassian.net/wiki/spaces/HPCWORKS/pages/1178075141/Understanding+Basic+InfiniBand+QoS</a></li> <li><a href="https://hpcadvisorycouncil.atlassian.net/wiki/spaces/HPCWORKS/pages/1177878529/Getting+Started+with+InfiniBand+QoS">https://hpcadvisorycouncil.atlassian.net/wiki/spaces/HPCWORKS/pages/1177878529/Getting+Started+with+InfiniBand+QoS</a></li> <li><a href="https://web-docs.gsi.de/~vpenso/notes/posts/hpc/network/infiniband/subnet-manager.html">https://web-docs.gsi.de/~vpenso/notes/posts/hpc/network/infiniband/subnet-manager.html</a></li> <li><a href="https://docs.nvidia.com/networking/display/mlnxofedv51258060/opensm">https://docs.nvidia.com/networking/display/mlnxofedv51258060/opensm</a></li> <li><a href="https://docs.nvidia.com/networking/display/mlnxofedv461000/qos+-+quality+of+service">https://docs.nvidia.com/networking/display/mlnxofedv461000/qos+-+quality+of+service</a></li> </ul> <p>Lustre discussions:</p> <ul> <li><a href="https://wiki.whamcloud.com/display/LNet/Lustre+QoS">https://wiki.whamcloud.com/display/LNet/Lustre+QoS</a> – see this!</li> <li><a href="https://groups.google.com/g/lustre-discuss-list/c/n6sdj-e5LNA">https://groups.google.com/g/lustre-discuss-list/c/n6sdj-e5LNA</a></li> <li><a href="https://www.mail-archive.com/lustre-discuss@lists.lustre.org/msg04092.html">https://www.mail-archive.com/lustre-discuss@lists.lustre.org/msg04092.html</a></li> <li><a href="https://admire-eurohpc.eu/wp-content/uploads/2023/12/Lustre-QoS-Barcelona-GA-Dec-2023.pptx.pdf">https://admire-eurohpc.eu/wp-content/uploads/2023/12/Lustre-QoS-Barcelona-GA-Dec-2023.pptx.pdf</a></li> </ul> <p>Intel Fabric Suite (configrms Lustre ServiceID)</p> <ul> <li><a href="https://www.intel.com/content/dam/support/us/en/documents/network-and-i-o/fabric-products/Intel_OP_FabricSuite_Fabric_Manager_UG_H76468_v15_0.pdf">https://www.intel.com/content/dam/support/us/en/documents/network-and-i-o/fabric-products/Intel_OP_FabricSuite_Fabric_Manager_UG_H76468_v15_0.pdf</a></li> </ul>]]></content><author><name></name></author><category term="infiniband"/><category term="infiniband"/><summary type="html"><![CDATA[Notes on configuring QoS in Infiniband]]></summary></entry><entry><title type="html">Prediction and Adaptation in Decisions</title><link href="https://ankushja.in/blog/2025/prediction-adaptation/" rel="alternate" type="text/html" title="Prediction and Adaptation in Decisions"/><published>2025-07-26T16:59:58+00:00</published><updated>2025-07-26T16:59:58+00:00</updated><id>https://ankushja.in/blog/2025/prediction-adaptation</id><content type="html" xml:base="https://ankushja.in/blog/2025/prediction-adaptation/"><![CDATA[<p>Some possibly non-coherent thoughts on decision-making:</p> <p>Any autonomous system must, by definition, take decisions. It is rational to consider the utility of the decision space and pick a nice point. We draw on our experience and simulate the impact of different decisions in our head, and then we pick one. Is that it?</p> <p>No, right? Decisions are not irrevocable. You can adapt. If you accidentally oversped, you can apply brakes.</p> <p>Predictive decisions rely on implicit or explicit modeling. Models are, in the best case, an nth-order approximation of a complex system, with ideally a decent predictive value and a low residual. Intuition, experience, and wisdom are also just models.</p> <p>Models are by definition imperfect—a perfect model would also necessitate a perfect simulation of all reality. But they can be, and are, more or less imperfect. We all start off with more imperfect models, and (unless maladaptive) use the residuals from using their predictions to refine them. The decision loop, therefore, may be defined to have these components:</p> <ol> <li>Observe inputs, and compute <code class="language-plaintext highlighter-rouge">decision = f(input, intent)</code></li> <li>Observe the impact of the decision and compute a course correction if necessary</li> <li>Use the residual to update your hypothesis</li> </ol> <p>Or a more formal attempt:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">:</span> <span class="n">m_init</span>   <span class="c1"># Our initial model
</span><span class="n">intent</span><span class="p">:</span> <span class="n">i_init</span>  <span class="c1"># Some mysterious missing ingredient
</span>
<span class="k">while</span> <span class="n">Alive</span><span class="p">:</span>
  <span class="n">reality</span> <span class="o">=</span> <span class="nf">input</span><span class="p">()</span>
  <span class="n">decision</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">reality</span><span class="p">,</span> <span class="n">intent</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
  <span class="n">impact</span> <span class="o">=</span> <span class="n">reality</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">decision</span><span class="p">)</span>
  <span class="n">error</span> <span class="o">=</span> <span class="n">intent</span> <span class="o">-</span> <span class="n">impact</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
  <span class="n">intent</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">reality</span><span class="p">,</span> <span class="n">impact</span><span class="p">)</span>
</code></pre></div></div> <h2 id="what-is-an-optimal-decision">What Is An Optimal Decision?</h2> <p>It is tempting to then say that the quality of the initial decision does not matter, because it can always be updated. That models the system as a stochastic process, and is true insofar as that holds/is a reasonable approximation. But that is not the case: human lifetimes are finite and there is a time cost and material cost of bad decisions, there is no recovering from jumping off a cliff, prior actions also affect other agents’ models (what we call reputation or trust).</p> <p>It may then be tempting to say that you want the best model before you take any decisions. But models are by definition updated by taking decisions. Scheduling of decisions is a useful escape hatch/degree of freedom: you may decide to read a book to have a better model before taking a decision with a bigger modeled impact. Scheduling is perhaps a meta-decision: choosing to <em>explore</em> (deferring the big decision) rather than <em>exploit</em>.</p> <p>Deferring is useful insofar as the marginal improvement in your model outweighs the opportunity cost of delaying a decision. Two examples of instances where deferring is bad:</p> <ol> <li>There exists no decision that meaningfully enhances the utility of the deferred decision</li> <li>The opportunity cost of deferment is large</li> </ol> <p><strong>Connections With Standard Terminology</strong> I think open-loop and closed-loop control in control theory are not appropriate parallels. What I am describing is maybe an adaptive closed-loop system? But an autonomous, adaptive, completely programmable closed-loop system where decisions update both the model and the intent. Or just intelligent and conscious life?</p> <h2 id="why-is-this-useful">Why Is This Useful</h2> <p><strong>How to design systems</strong>. If a system requires some information that is, by definition, not available at bootstrap, adaptive mechanisms are necessary to solve the problem.</p> <p><strong>Autonomous intelligence, maybe?</strong> With current ML models, backpropagation is a progressive hypothesis refinement loop, but without an intent. And then model weights are frozen and they are tasked with prediction. But being static, they are not refined, unless we account for periodic batch refinement that is conducted with additional data gathered since the previous run.</p> <p>Are models sufficiently adaptive? Is it possible that even with static weights, they learn to simulate memories etc. within those weights? What are the limits of computations that an algorithm running on top of a static machine can express, versus those of an algorithm that can mutate the machine itself?</p>]]></content><author><name></name></author><category term="systems,"/><category term="ml"/><category term="reasoning"/><category term="ml"/><category term="systems"/><summary type="html"><![CDATA[How to model decision-making itself?]]></summary></entry><entry><title type="html">Notes on Deepseek 3FS Filesystem</title><link href="https://ankushja.in/blog/2025/notes-on-deepseek-3fs/" rel="alternate" type="text/html" title="Notes on Deepseek 3FS Filesystem"/><published>2025-03-02T14:19:21+00:00</published><updated>2025-03-02T14:19:21+00:00</updated><id>https://ankushja.in/blog/2025/notes-on-deepseek-3fs</id><content type="html" xml:base="https://ankushja.in/blog/2025/notes-on-deepseek-3fs/"><![CDATA[<p>This is just me making some quick notes on the 3FS Parallel Filesystem from Deepseek<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>. Caveat that while I have opinions on all systems, filesystems is strictly not my day job and I have to go back and think about a bunch of things and it doesn’t quite work, and this post will likely have a bunch of mistakes.</p> <h1 id="services-in-3fs">Services in 3FS</h1> <ul> <li>Cluster manager: highly available, manages membership, config etc (uses zookeeper?)</li> <li>Metadata service: uses FoundationDB</li> <li>Storage service (chunk store?)</li> <li>Client (two implementations: FUSE-based, and a more performant one.)</li> </ul> <h1 id="metadata-in-3fs">Metadata in 3FS</h1> <h3 id="the-ongoing-metadata-debate">The Ongoing Metadata Debate</h3> <p>Whether we need object stores or filesystem semantics has been a topic of conversation recently<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>. My own views so far:</p> <ul> <li>I buy the argument that data accesses during a training run do not need a namespace. Maybe the namespace can be <em>batch-updated</em> later on, if it gets in the way and does not provide the required performance.</li> <li>I feel that the usability argument still applies. At some point, you need to think about what does all the data mean, what to keep around, what to prune. There are a million reasons – legal, regulatory, financial, just basic IT maintenance that require metadata. Long-term, it is easy to think about things as a group or a hierarchy.</li> </ul> <p>I think performant fileystem namespaces is doable. It may get needlessly hard if you tie yourself to a spec or a standard. That is because this is in flux, and we do not yet have unanimous agreement on what the standard should look like.</p> <h3 id="the-3fs-approach">The 3FS Approach</h3> <p>They use a key-value model for their metadata, built on top of FoundationDB. Each key represents an inode.</p> <p>FoundationDB, as an aside, is a very interesting database. It is like a distributed RocksDB with support for strict serializability in transactions. This is interesting to me — normally you think of KV stores as single-node storage backends for DBMSes to use. Transactions are implemented at a SQL level. FDB implements transactions at the KV level, but is supposed to be a lower-level database you layer on top of. (Aside: I wonder what the end-to-end principle says about the correct layering). It is like a persistent distributed software transactional memory, that tries to be lock-free, with optimistic and multi-version concurrency control.</p> <ul> <li>File inodes are <code class="language-plaintext highlighter-rouge">INOD&lt;inode_id&gt;</code>, mapped to ownership, permissions, times., and chunk information etc. for files. Interestingly, they encode <code class="language-plaintext highlighter-rouge">inode_id</code> in little-endian to spread inodes across FDB nodes. Directory inodes begin with <code class="language-plaintext highlighter-rouge">DENT</code>, have bidirectional links to parents to ensure no loops.needs to be and should be super-fast.</li> <li><code class="language-plaintext highlighter-rouge">fstat</code>, <code class="language-plaintext highlighter-rouge">lookup</code>, <code class="language-plaintext highlighter-rouge">listdir</code> etc. invoke read-only txns. <code class="language-plaintext highlighter-rouge">crate</code>, <code class="language-plaintext highlighter-rouge">link</code> etc. invoke read-write txns.</li> </ul> <h3 id="state-in-3fs">State in 3FS</h3> <p>3FS metadata stores are stateless. Any operation is a self-contained transaction.</p> <p>The metadata service does store file descriptors for files opened in write mode, but not in read mode. This helps with bootstrapping training jobs. This IMO is super important!! Any parallel job, when bootstrapping, needs to retrieve a large number of files in read-only mode. This should be super-fast, but is not so with Lustre. I vaguely recall someone mentioning that they had to hack on a cache on top of Lustre to push <code class="language-plaintext highlighter-rouge">.so</code> libraries to MPI ranks, and thinking that this feels like a fundamental flaw in what is supposed to be a parallel filesystem.</p> <p>Question: how do you handle a write request for a file that is currently open in read-only mode? Ideally you need to track the readers and revoke their lease, but that requires maintaining state at the metadata layer? I think that’s done by tracking versions?</p> <h2 id="chunk-store">Chunk Store</h2> <p>This is relatively straightforward. It is per-node, and comes with a RocksDB instance for chunk metadata. Chunk metadata is cached in-memory. They have 11 chunk sizes from 64 KiB to 64 MiB. I don’t think this is a big deal but metadata shouldn’t be too much, even with 64KiB chunks, it is a little surprising that they went for this number of chunk sizes. But eh. Updates are CoW – old chunks remain valid until update completes.</p> <h2 id="chain-replication">Chain Replication</h2> <p>They use CRAQ (Chained Replication with Apportioned Queries) for replication. This is just a fancy way of saying that any replica can respond to a read request, with the catch being that you may get a stale version. A node may have a committed version of a block and a pending version. If so, it lets the requester know the existence of both versions, and the decision on whether to tolerate staleness or try again is left to the requester. Note that this is different from the case where a chain replica does not even know of the existence of an update – I don’t know if stale reads are tolerated in that case (or maybe version numbers are used to read a consistent snapshot).</p> <h2 id="zero-copy-in-fuse">Zero-copy in FUSE!?</h2> <p>They use FUSE for clients, so as to not deal with debugging kernel panics. They define an interface called <code class="language-plaintext highlighter-rouge">USRBIO</code>, for zero-copy interaction between the userspace and the FUSE layer. <code class="language-plaintext highlighter-rouge">USRBIO</code> is inspired by <code class="language-plaintext highlighter-rouge">io-uring</code> (or the Verbs API for that matter). The FUSE process manages Verbs-registered memory and submission/completion rings, and does the dispatch etc. These zero-copy ops are only used for the data path, and metadata ops still go through regular FUSE APIs.</p> <h2 id="misc">Misc</h2> <ul> <li>Codebase is mostly C++ with some Rust.</li> <li>They use <code class="language-plaintext highlighter-rouge">P</code><sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">3</a></sup> to verify their protocols. <code class="language-plaintext highlighter-rouge">P</code> is apparently a formal verification language for event-driven distributed services. Very cool!</li> <li>They seem to use <code class="language-plaintext highlighter-rouge">flatbuffers</code> for serdes and their own RDMA/RPC wrappers on top of the <code class="language-plaintext highlighter-rouge">verbs</code> interface. There’s a lot of code there and I just briefly skimmed through it.</li> <li>They heavily use <code class="language-plaintext highlighter-rouge">folly</code>, Facebook’s assorted library of C++ abstractions (including coroutines).</li> </ul> <h1 id="epilogue">Epilogue</h1> <p>Not sure what to make of this. Writing a parallel filesystem is a massive undertaking. While metadata bottlenecks is a well-known problem in parallel filesystems, offloading it entirely to a DB like FoundationDB is an interesting choice. I have been trying to revisit how Colossus/Tectonic manage their metadata, and it is Bigtable and ZippyDB respectively. Ceph is pretty much the only open-source filesystem to support multiple metadata servers (Lustre is unwieldy in multiple ways). 3FS is optimized for RDMA fabrics over the data path, and makes subtle choices (like cheap metadata reads) to optimize for a large parallel job bootstrapping. I remember reading somewhere that it is designed for small random accesses, and I don’t really see why that is the case. I will end with the caveat that there are a lot of things to keep straight in distributed/parallel filesystem discussions, I don’t really work on these, and this post probably has a bunch of mistakes.</p> <p>(Oh their design notes do say that they enable random access to training samples, I don’t see how they optimize for random accesses, maybe they mean that their system will transfer partial chunks and not do aggressive prefetching etc?)</p> <h1 id="references">References</h1> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>https://github.com/deepseek-ai/3FS <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>https://blog.glennklockwood.com/2025/02/llm-training-without-parallel-file.html <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>https://github.com/p-org/P <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="systems"/><category term="filesystems"/><category term="storage"/><summary type="html"><![CDATA[Notes on the Fire-Flyer Filesystem by Deepseek]]></summary></entry><entry><title type="html">On The Universality of Query Languages</title><link href="https://ankushja.in/blog/2025/universality-query-languages/" rel="alternate" type="text/html" title="On The Universality of Query Languages"/><published>2025-02-06T15:08:30+00:00</published><updated>2025-02-06T15:08:30+00:00</updated><id>https://ankushja.in/blog/2025/universality-query-languages</id><content type="html" xml:base="https://ankushja.in/blog/2025/universality-query-languages/"><![CDATA[<p>This is an initial quick draft of this line of thought, written 16 hours before a paper deadline I have things to do about (that has nothing to do with query languages). It will be rushed and half-baked, and surreptitiously refined later.</p> <p>Goal for this post: let us try justifying SQL. Why it exists, why is it in a specific form etc.</p> <h2 id="sql-vs-relational-algebra">SQL vs Relational Algebra</h2> <p>I think SQL is made-up and non-essential. It is syntactic sugar over relational algebra. Other declarative interfaces may be more convenient abstractions — I personally prefer dataframes and chaining of expressions.</p> <p>If you think of the query plan as a dataflow tree leading up to a root, SQL is essentially a traversal over that tree, like in-order, pre-order etc. The order SQL follows, specifically, may be called a <em>Weird Arbitrary Traversal</em> (or <em>WAT</em>). That the query planning infra evolved to reflect dataflow is not surprising, data movement is expensive, be it across functions or machines, and the more data you discard closer to the source the better off you are.</p> <p>These pedantic distinctions are important, because they enable us to reason about</p> <h2 id="on-the-universality-of-relational-algebra">On the Universality of Relational Algebra?</h2> <p>Okay so why does relational algebra exist in the form it does?</p> <p>As a lower bound on this argument, a query interface could just be say… C. You write a blob, machine runs blob, you get output.</p> <p>We do declarative interfaces to make life easier given certain domain-specific constraints. In the relational world, it is:</p> <ol> <li>Leveraging the relational/tabular data model.</li> <li>Leveraging distributed cluster resources.</li> <li>Leveraging fine-grained scheduling, concurrency etc.</li> <li>Getting easy access to indexes etc.</li> <li>Enabling reduced data movement by exposing primitives that capture data flow</li> <li>Enabling query optimization by exposing primitives that make it easier to reason about ordering and statistics</li> <li>Enable reasoning about partitioning and shuffling using key constraints and joins</li> </ol> <h2 id="do-relational-operators-do-these-things">Do Relational Operators Do These Things?</h2> <p>To a large extent, yes. That is why relational algebra endures. SQL just pretends to be inseparable from that and most people do not ask too many questions.</p> <p>You always need escape hatches. That is why UDFs exist. But beyond a point, they hinder the query planning infra’s ability to reason about what the blob does.</p> <h2 id="who-deserves-to-be-in-the-club">Who Deserves To Be In The Club?</h2> <p>What operators should be in this club?</p> <ul> <li>Can we justify the existence of all existing operators?</li> <li>Are there new ones that should be there but are not?</li> <li>Under what models do we need radically different solutions?</li> </ul> <p>Relational algebra checks out as it is essentially set theory. Given a table, you can slice it horizontally or vertically. Indexing helps with horizontal slicing. Vertical slicing is harder in row-based stores but column-based stores have solutions. Selection and projection map nicely to dataflow, indexing etc. Division seems to be the only relational operator not directly used in query plans.</p> <h2 id="where-am-i-getting-at">Where Am I Getting At?</h2> <p>There exist data models (such as multidimensional array-based scientific data) that are not relational. Graphs are one example. Nothing here is really new.</p> <p>The question I am trying to answer is: what is the set of ideas that lead you to the perfect operators for these domains? Do they exist? Are they in conflict with relational algebra? Or can they be members of the extended family?</p> <p><em>Note to self: read referenced material</em> <sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup><sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup><sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup><sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">4</a></sup></p> <h2 id="references">References</h2> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>SciQL, a query language for science applications, Proceedings of the EDBT/ICDT 2011 Workshop on Array Databases, 2011, https://dl.acm.org/doi/10.1145/1966895.1966896 <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>MeshSQL: The query language for simulation mesh data, Information Sciences, 2004, https://www.sciencedirect.com/science/article/pii/S0020025503001981 <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>Toward unstructured mesh algebra and query language, Proceedings of the 2014 SIGMOD PhD symposium, 2014, https://dl.acm.org/doi/10.1145/2602622.2602626o <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:4"> <p>TileDB ∙ Designed for Discovery, https://tiledb.com/ <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="philosoraptormode"/><category term="sql"/><summary type="html"><![CDATA[Why is SQL what it is? What motivates a different query language?]]></summary></entry><entry><title type="html">Are All Networks Just Tradeoffs?</title><link href="https://ankushja.in/blog/2024/network-tradeoffs/" rel="alternate" type="text/html" title="Are All Networks Just Tradeoffs?"/><published>2024-12-07T00:58:30+00:00</published><updated>2024-12-07T00:58:30+00:00</updated><id>https://ankushja.in/blog/2024/network-tradeoffs</id><content type="html" xml:base="https://ankushja.in/blog/2024/network-tradeoffs/"><![CDATA[<p><a href="https://ankushja.in/blog/2024/credits-flow-congestion/">Part 1 here</a>.</p> <p>This post will explore the following thesis:</p> <ol> <li>All networks and variants are tradeoffs.</li> <li>If there are tradeoffs, there is no permanent winning. You are always tuning to chase <em>the window</em>.</li> </ol> <p>Disclaimer: this could be the most obvious statement in the world. Or maybe deep within the symbolic mines of queuing and scheduling, someone has said something that disproves all of it. Or maybe that that statement is obvious but the arguments below are flawed. I have no idea — this blog does not come with any guarantees for rigor or scrutiny.</p> <h2 id="context-thinking-about-cbfc-vs-pfc">Context: Thinking About CBFC vs PFC</h2> <p>The thing in the back of my mind recently has been — why does everyone complain about PFC and RoCEv2, and why do they not complain about Infiniband and CBFC (Credit-based Flow Control). Why could RoCEv2 not adopt CBFC? What do you gain and what do you lose? Do you still need higher-level congestion control with CBFC?</p> <h2 id="cbfc-is-not-a-magic-pill">CBFC Is Not A Magic Pill</h2> <p>An upper bound to CBFC goodness is much easier to establish than its precise extent.</p> <p>CBFC is not a magic pill. It can still lead to credit loops, head-of-line blocking, buffer overflows, packet loss emanating from it, and so on. It is also amenable to tuning: routing, topologies, credit management schemes etc. to reduce the likelihood of bad things happening.</p> <p>CBFC absolutely provides no theoretical guarantee (I’m not talking about a bounds-type argument: under X flows and Y buffer sizes you prove a Z\% upper bound on packet loss). Also not everyone means the same thing when they talk about CBFC — the Infiniband spec on this is not very prescriptive — my understanding is that it describes packet formats, and some basic mechanics, but still leaves a lot of room for vendors to do better.</p> <h2 id="guarantees-are-expensive">Guarantees Are Expensive</h2> <p>You could provide a lot of guarantees by implementing a network as an all-to-all network of separate links. That is essentially what a crossbar is. But we want to optimize for cost. So we do tiers and routing and non-uniform bandwidth and all that stuff. You lose out on worst-case performance but that’s the only way to get systems to scale.</p> <p>Turns out that this applies for everything — including tail latencies, jitter etc. The only way to guarantee that you will move a packet in a predictable timely manner is to explicitly carve out room for that packet on the path before sending it out. If you care about maintaining a high utilization or cost or scalability, this is bad.</p> <p>Given a guarantee, you can always make an argument that “we can relax this guarantee a little and get a lot more performance in the common case.” This is statistical multiplexing or oversubscription or optimistic concurrency control or whatever. These are incredibly important — these thoughtful relaxations are the reason that systems work and can be built for the prices that’re built for. But it is always nice to be explicit about what you are losing in return.</p> <h2 id="overloading-creates-more-risks">Overloading Creates More Risks</h2> <p>As the goal of this exercise was to understand CBFC, let us compare it with sender-driven mechanisms. Sender-driven congestion control overloads certain signals to infer network state — RTT and packet loss seem to be two of them. This works until something happens that changes the meaning of these numbers — bufferbloat being one example. An advantage, in principle, of CBFC is that it is explicitly communicating actual network state, so theoretically, it should be robust to some such issues. I do not know if that is actually realized in practice.</p> <p>This is in no way trashing sender-driven mechanisms. A good system is one that gets the job done — clean conscience and mathematical elegance are the domains of whiteboard hoggers. The end-to-end principle and this layered approach to TCP/IP has taken us a long long long way. Overloading those signals is the practical thing to do. (Also note that I’m conflating flow control with congestion control — CBFC is very much the former, but I guess it dictates and comes bundled with a different congestion control in IB with ECNs and injection throttling).</p> <h2 id="expectations-for-future-congestion-control">Expectations for Future Congestion Control</h2> <p>This post is a precursor to me trying to understand all the cool new things in datacenter fabrics — Omnipath, Slingshot, UltraEthernet, maybe Globally Scheduled Ethernet?</p> <p>If these arguments hold, none of these systems’ mechanisms will be perfect. There will always be cases where Bad Things$^{TM}$ happen. Part of the argument is that that may be okay, and an evaluation of their properties must be holistic.</p> <h2 id="some-degree-of-tuning-is-okay">Some Degree Of Tuning Is Okay?</h2> <ul> <li>I can not pick an outfit that works in all weathers. I am destined to keep tuning.</li> <li>Some tuning is worse than others. If I wore an outfit that had only one shoe, I would have to hop and keep swapping my shoe from one foot to the other.</li> <li>An outfit that covers the expected swings over one day is sufficient for an outfit.</li> <li>A bag that covers the expected swings over one week is sufficient for a short trip.</li> <li>A wardrobe that covers the expected swings over the year in Pittsburgh is sufficient for most other cases.</li> </ul> <p>What are the takeaways for systems?</p> <ul> <li>We are destined to tune. We should plan for that.</li> <li>It would be nice if we understood systems in terms of their coverage of design space.</li> <li>Nothing in this discussion rules out the existence of systems that cover strictly more of the design space than others. Probably someone has and/or will prove that certain aspects are pareto-optimal. But it’s still a small sheet over massive legs.</li> </ul> <h2 id="chasing-the-global-optima">Chasing The Global Optima</h2> <p>Network sharing and scheduling mechanisms are probably by far the most well-studied and deployed examples of a distributed system trying to construct/reach a global optimum, and both mathematical and practical arguments of the challenges that comes with.</p> <p>All systems would benefit from better decisions. Better decisions are enabled by a better view of the system state. But constructing this system state may be prohibitively expensive. It may also be a moving target. It will definitely have some uncertainty bounds because physics. It may also be possible that explicitly constructing the system state is not necessary — we can apparently go quite a bit with individual actors acting on simple rules. (Something about game theory and cooperative games comes to mind but I’m already wayyyy past my depth here).</p>]]></content><author><name></name></author><category term="networks"/><category term="networks"/><summary type="html"><![CDATA[Or, are we destined to tune?]]></summary></entry><entry><title type="html">Credits, Flow, and Congestion Control in Infiniband</title><link href="https://ankushja.in/blog/2024/credits-flow-congestion/" rel="alternate" type="text/html" title="Credits, Flow, and Congestion Control in Infiniband"/><published>2024-12-04T19:00:36+00:00</published><updated>2024-12-04T19:00:36+00:00</updated><id>https://ankushja.in/blog/2024/credits-flow-congestion</id><content type="html" xml:base="https://ankushja.in/blog/2024/credits-flow-congestion/"><![CDATA[<p>Things keep happening in datacenter networks. There (used to be) Ethernet, there’s Infiniband, Omnipath<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> (and its predecessors and successors), Slingshot<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>, UltraEthernet<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>, and now <em>Globally Scheduled Ethernet</em><sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">4</a></sup>. I don’t get why they all need to exist concurrently and this is an initial attempt at unraveling this for myself.</p> <p>Step 1 in this process is understanding Infiniband. Hyperscalers seem to like Infiniband and RDMA, but they also like their IP addresses and routing tables. RoCE and ROCEv2 were attempts to bridge the gaps, but they turned out to have problems. At this point, I know the talking points everyone rehashes — PFC storms, HoL blocking, deadlocks… but I don’t really understand any of it.</p> <p>From my understanding, all of the changes in RoCEv2 were necessitated because it is hard to get RDMA to work over lossy networks. (As an aside, it seems to me that there is no such thing as a truly lossless network, but you can build a pretty good illusion of one with two properties: 1. Reduce the likelihood of packet loss, and 2. Handle retransmissions transparently at some lower layer). I haven’t heard anyone complain about how flow control works in infiniband, so the key is maybe to understand it. This post is an attempt at that.</p> <h1 id="credit-based-flow-control-in-infiniband">Credit-based Flow Control in Infiniband</h1> <p>This is all based off slides here: <sup id="fnref:5"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">5</a></sup>.</p> <h2 id="virtual-lanes-and-service-levels">Virtual Lanes and Service Levels</h2> <p>Credits are maintained per-VL on each HCA. VLs/SLs are technically different but equivalent for now. They are priority classes — Infiniband supports up to 16. VL15 is reserved for subnet management traffic, while the others are available for regular data. The difference is that the application requests service levels, and the SL-VL mapping is a management decision handled presumably by the subnet manager.</p> <h2 id="basic-numbers">Basic Numbers</h2> <ul> <li>Each <code class="language-plaintext highlighter-rouge">Flow Control Block</code> is 64B. One 64B send requires one credit to be authorized.</li> <li>A VL will issue a maximum of 2048 credits, which translates to a 128KB receive buffer. <h2 id="cbfc-actual">CBFC Actual</h2> <p>There are 3 main terms: <code class="language-plaintext highlighter-rouge">ABR</code>, <code class="language-plaintext highlighter-rouge">FCCL</code>, <code class="language-plaintext highlighter-rouge">FCTBS</code>.</p> </li> <li><code class="language-plaintext highlighter-rouge">FCCL</code>: the credit limit (the max point up to which the sender has been authorized to send).</li> <li><code class="language-plaintext highlighter-rouge">ABR</code>: total blocks received at the receiver so far.</li> <li><code class="language-plaintext highlighter-rouge">FCTBS</code>: total blocks sent.</li> </ul> <p><code class="language-plaintext highlighter-rouge">FCTBS</code> - <code class="language-plaintext highlighter-rouge">ABR</code>: blocks in transit on the wire. <code class="language-plaintext highlighter-rouge">FCCL</code> - <code class="language-plaintext highlighter-rouge">FCTBS</code>: remaining credits for the sender. A send will be permitted if the size is smaller than this limit.</p> <h1 id="flow-control-vs-congestion-control">Flow Control vs Congestion Control</h1> <p>Flow control makes infiniband largely and inherently lossless. Rare occasions that cause packet corruption etc. may require retransmissions. The fabric will do retransmissions for you if <code class="language-plaintext highlighter-rouge">Reliable Connected</code> was requested. CBFC kicks in regardless of whether you use RC or UC or UD. I haven’t looked into how retransmissions for <code class="language-plaintext highlighter-rouge">RC</code> are managed.</p> <p>Infiniband also has congestion control on top of flow control. Why both need to exist is not entirely clear to me yet. What I do know is that IB employs some variant of <code class="language-plaintext highlighter-rouge">ECN (Explicit Congestion Notification)</code> to help detect congestion (<code class="language-plaintext highlighter-rouge">FECN</code> and <code class="language-plaintext highlighter-rouge">BECN</code>). I don’t know what the endpoints do in response to ECNs.</p> <h1 id="questions-for-myself">Questions For Myself</h1> <ul> <li>Why is it hard to retrofit CBFC on to ethernet?</li> <li>Why don’t all datacenter fabrics use CBFC?</li> <li>How does CBFC compare to loss-based congestion control. <h1 id="references">References</h1> </li> </ul> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:2"> <p>What If Omni-Path Morphs Into The Best Ultra Ethernet?, , 2024, https://www.nextplatform.com/2024/06/26/what-if-omni-path-morphs-into-the-best-ultra-ethernet/ <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>Cray’s Slingshot Interconnect Is At The Heart Of HPE’s HPC And AI Ambitions, , 2022, https://www.nextplatform.com/2022/01/31/crays-slingshot-interconnect-is-at-the-heart-of-hpes-hpc-and-ai-ambitions/ <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:1"> <p>UltraEthernet: Overview of and Motivation for the Forthcoming Ultra Ethernet Consortium Specification, , , <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:4"> <p>Whitepaper on Globally Scheduled Ethernet, , 2024, https://regmedia.co.uk/2024/11/26/china_mobile_gse_whitepaper.pdf <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:5"> <p>Infiniband Credit-Based Link-Layer Flow-Control, , 2014, https://www.ieee802.org/1/files/public/docs2014/new-dcb-crupnicoff-ibcreditstutorial-0314.pdf <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="systems"/><category term="networks"/><summary type="html"><![CDATA[Notes on CBFC, lossless fabrics, receiver-driven congestion control etc.]]></summary></entry><entry><title type="html">Notes on Web Pages and CMU Infra</title><link href="https://ankushja.in/blog/2024/cmu-web-pages.md/" rel="alternate" type="text/html" title="Notes on Web Pages and CMU Infra"/><published>2024-11-29T18:11:12+00:00</published><updated>2024-11-29T18:11:12+00:00</updated><id>https://ankushja.in/blog/2024/cmu-web-pages.md</id><content type="html" xml:base="https://ankushja.in/blog/2024/cmu-web-pages.md/"><![CDATA[<p>Infra for hosting web pages on CMU web servers is a little complicated and confusing, and I waste some time figuring it out every time I need to change something. These are notes to make my life easier in the future, and may be relevant for others. This is from the perspective of an ECE student, adapt to your needs.</p> <h2 id="afs-cells">AFS Cells</h2> <p>I get to have a home directory on two CMU cells – <code class="language-plaintext highlighter-rouge">andrew.cmu.edu</code> and <code class="language-plaintext highlighter-rouge">ece.cmu.edu</code>. I don’t know how to discover all the cells you have a home directory in.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ssh ankushj@unix.andrew.cmu.edu # give them your andrew password
$ pwd
/afs/andrew.cmu.edu/usr18/ankushj
$ cd /afs/ece.cmu.edu/usr/ankushj
$ ls
Permission denied
$ aklog ece.cmu.edu
$ ls
top_secret_infiniband_content.txt
$ tokens
&lt;all the cells I'm authenticated for&gt;

# random AFS commands
$ fs listaliases
$ fs listquota
</code></pre></div></div> <h2 id="hosting-on-ece">Hosting on ECE</h2> <p>This is straightforward. Your <code class="language-plaintext highlighter-rouge">public_html</code> is available on <code class="language-plaintext highlighter-rouge">users.ece.cmu.edu/~ankushj</code></p> <p>ECE also respects <code class="language-plaintext highlighter-rouge">.htaccess</code></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ls -a /path/to/ece/homedir/public_html
.htaccess index.html
</code></pre></div></div> <h2 id="hosting-on-andrew">Hosting on Andrew</h2> <p>This is more confusing. Target address is <code class="language-plaintext highlighter-rouge">https://www.andrew.cmu.edu/user/ankushj/</code>.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ls -a /path/to/andrew/homedir/www
.htaccess index.html
</code></pre></div></div> <ol> <li>Andrew does not use <code class="language-plaintext highlighter-rouge">.htaccess</code>.</li> <li><code class="language-plaintext highlighter-rouge">index.html</code> is not automatically available. You have to go to <code class="language-plaintext highlighter-rouge">https://www.andrew.cmu.edu/server/publish.html</code>, type your username, hit publish, and the data gets copied to some “real hosting destination”.</li> <li><code class="language-plaintext highlighter-rouge">.unpublish</code> is a thing<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup></li> </ol> <h2 id="redirects">Redirects</h2> <p>On ECE, I can set up a HTTP-level redirect via <code class="language-plaintext highlighter-rouge">.htaccess</code>.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RedirectMatch 301 ^/$ https://my.real.website
</code></pre></div></div> <p>I previously tried the following, but it would redirect to <code class="language-plaintext highlighter-rouge">https://my.real.website~ankushj</code>. I am pretty sure that ChatGPT is just giving me a stupid redirect command, but the version above works and the version below does not — that’ll have to do for now.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Redirect 301 / https://my.real.website
</code></pre></div></div> <p>From Andrew, I had to set up a HTTP redirect.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
        &lt;meta http-equiv="refresh" content="0; url=https//my.real.website"&gt;
            &lt;title&gt;Redirecting...&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
        &lt;p&gt;If you are not redirected, &lt;a href="https://my.real.website"&gt;click here&lt;/a&gt;.&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre></div></div> <h2 id="troubleshooting">Troubleshooting</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Permissions
$ fs sa www system:anyuser rl
</code></pre></div></div> <h2 id="references">References</h2> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>https://www.cmu.edu/computing/services/comm-collab/websites/user-course-web/how-to/publish.html <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="web"/><category term="web"/><summary type="html"><![CDATA[Dealing with AFS, cells, permissions etc.]]></summary></entry><entry><title type="html">Inscrutable Coredump v. Unmoveable Grad Student</title><link href="https://ankushja.in/blog/2024/inscrutable-core-dump/" rel="alternate" type="text/html" title="Inscrutable Coredump v. Unmoveable Grad Student"/><published>2024-07-09T19:24:13+00:00</published><updated>2024-07-09T19:24:13+00:00</updated><id>https://ankushja.in/blog/2024/inscrutable-core-dump</id><content type="html" xml:base="https://ankushja.in/blog/2024/inscrutable-core-dump/"><![CDATA[<p>Situation: we have a core dump that is shy to reveal its inner workings. The goal is to extract some more information from this core dump, using fancier analyses. The core dump is 1.2GB in size, so I know that there is some insight in there, it is just buried.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) bt</span><span class="w">
</span>#0<span class="w">  </span><span class="mh">0x00007fbaa4653c30</span><span class="w"> </span>in<span class="w"> </span>??<span class="w"> </span><span class="p">()</span><span class="w">
</span>#1<span class="w">  </span><span class="mh">0x0000000000000000</span><span class="w"> </span>in<span class="w"> </span>??<span class="w"> </span><span class="p">()</span><span class="w">
</span></code></pre></div></div> <p>Since we have an intact <code class="language-plaintext highlighter-rouge">$pc</code> (which refers to <code class="language-plaintext highlighter-rouge">%rip</code>), we can figure out the instructions it was executing.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) disassemble $pc-20,$pc+20</span><span class="w">
</span>Dump<span class="w"> </span>of<span class="w"> </span>assembler<span class="w"> </span>code<span class="w"> </span>from<span class="w"> </span><span class="mh">0x7fbaa4653c1c</span><span class="w"> </span>to<span class="w"> </span><span class="mh">0x7fbaa4653c44</span>:<span class="w">
   </span><span class="mh">0x00007fbaa4653c1c</span>:<span class="w">  </span>add<span class="w">    </span><span class="nv">%al</span><span class="p">,(</span><span class="nv">%rax</span><span class="p">)</span><span class="w">
   </span><span class="mh">0x00007fbaa4653c1e</span>:<span class="w">  </span>jmp<span class="w">    </span><span class="mh">0x7fbaa4653a51</span><span class="w">
   </span><span class="mh">0x00007fbaa4653c23</span>:<span class="w">  </span>nopl<span class="w">   </span><span class="mh">0x0</span><span class="p">(</span><span class="nv">%rax</span><span class="p">,</span><span class="nv">%rax</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="w">
   </span><span class="mh">0x00007fbaa4653c28</span>:<span class="w">  </span>mov<span class="w">    </span><span class="mh">0x98</span><span class="p">(</span><span class="nv">%r12</span><span class="p">),</span><span class="nv">%rax</span><span class="w">
</span>=&gt;<span class="w"> </span><span class="mh">0x00007fbaa4653c30</span>:<span class="w">  </span>cmpb<span class="w">   </span>$0x48,(%rax)<span class="w">
   </span><span class="mh">0x00007fbaa4653c33</span>:<span class="w">  </span>jne<span class="w">    </span><span class="mh">0x7fbaa4653b90</span><span class="w">
   </span><span class="mh">0x00007fbaa4653c39</span>:<span class="w">  </span>movabs<span class="w"> </span>$0x50f0000000fc0c7,%rdx<span class="w">
   </span><span class="mh">0x00007fbaa4653c43</span>:<span class="w">  </span>cmp<span class="w">    </span><span class="nv">%rdx</span><span class="p">,</span><span class="mh">0x1</span><span class="p">(</span><span class="nv">%rax</span><span class="p">)</span><span class="w">
</span>End<span class="w"> </span>of<span class="w"> </span>assembler<span class="w"> </span>dump.<span class="w">
</span></code></pre></div></div> <p>Let us inspect the registers.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) info reg</span><span class="w">
</span>rax<span class="w">            </span><span class="mh">0x323338342034342e</span><span class="w">  </span><span class="mi">3617296722238387246</span><span class="w">
</span>rbx<span class="w">            </span><span class="mh">0x7fff678ebb50</span><span class="w">      </span><span class="mi">140734930795344</span><span class="w">
</span>rcx<span class="w">            </span><span class="mh">0x7fba82086120</span><span class="w">      </span><span class="mi">140439022231840</span><span class="w">
</span>rdx<span class="w">            </span><span class="mh">0x1</span><span class="w">                 </span><span class="mi">1</span><span class="w">
</span>rsi<span class="w">            </span><span class="mh">0x1</span><span class="w">                 </span><span class="mi">1</span><span class="w">
</span></code></pre></div></div> <p>Okay so our <code class="language-plaintext highlighter-rouge">%rax</code> was clearly a gibberish address, no wonder dereferencing it failed. Now the question is what source file/line was mapped to <code class="language-plaintext highlighter-rouge">$pc</code>. ChatGPT says that the following can work:</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) list *$pc</span><span class="w">
</span>&lt;no<span class="w"> </span>output&gt;<span class="w">
</span><span class="gp">(gdb) info symbol $pc</span><span class="w">
</span>No<span class="w"> </span>symbol<span class="w"> </span>matches<span class="w"> </span>$pc.<span class="w">
</span></code></pre></div></div> <p>ChatGPT also says that we can also dereference addresses using these, but first we need to know what library is laid out in our memory, and at what offset. Noting these down for later.</p> <div class="language-session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$ addr2line -e /path/to/your/executable 0xADDRESS</span><span class="w">
</span><span class="gp">$ objdump -d -S /path/to/your/executable</span><span class="w">
</span></code></pre></div></div> <p>Some more useful information, saving for later.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) info frame 0</span><span class="w">
</span>Stack<span class="w"> </span>frame<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebaf8</span>:<span class="w">
 </span>rip<span class="w"> </span>=<span class="w"> </span><span class="mh">0x7fbaa4653c30</span>;<span class="w"> </span>saved<span class="w"> </span>rip<span class="w"> </span>=<span class="w"> </span><span class="mh">0x0</span><span class="w">
 </span>called<span class="w"> </span>by<span class="w"> </span>frame<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebb00</span><span class="w">
 </span>Arglist<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebae8</span><span class="p">,</span><span class="w"> </span>args:<span class="w">
 </span>Locals<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebae8</span><span class="p">,</span><span class="w"> </span>Previous<span class="w"> </span>frame's<span class="w"> </span>sp<span class="w"> </span>is<span class="w"> </span><span class="mh">0x7fff678ebaf8</span><span class="w">
 </span>Saved<span class="w"> </span>registers:<span class="w">
  </span>rip<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebaf0</span><span class="w">
</span><span class="gp">(gdb) info frame 1</span><span class="w">
</span>Stack<span class="w"> </span>frame<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebb00</span>:<span class="w">
 </span>rip<span class="w"> </span>=<span class="w"> </span><span class="mh">0x0</span>;<span class="w"> </span>saved<span class="w"> </span>rip<span class="w"> </span>=<span class="w"> </span><span class="mh">0x0</span><span class="w">
 </span>caller<span class="w"> </span>of<span class="w"> </span>frame<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebaf8</span><span class="w">
 </span>Arglist<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebaf0</span><span class="p">,</span><span class="w"> </span>args:<span class="w">
 </span>Locals<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebaf0</span><span class="p">,</span><span class="w"> </span>Previous<span class="w"> </span>frame's<span class="w"> </span>sp<span class="w"> </span>is<span class="w"> </span><span class="mh">0x7fff678ebb00</span><span class="w">
 </span>Saved<span class="w"> </span>registers:<span class="w">
  </span>rip<span class="w"> </span>at<span class="w"> </span><span class="mh">0x7fff678ebaf8</span><span class="w">
</span><span class="gp">(gdb) info frame 2</span><span class="w">
</span>No<span class="w"> </span>frame<span class="w"> </span>at<span class="w"> </span>level<span class="w"> </span><span class="mi">2</span>.<span class="w">
</span></code></pre></div></div> <p>Let’s look at shared memory mappings now.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) info shared</span><span class="w">
</span>No<span class="w"> </span>shared<span class="w"> </span>libraries<span class="w"> </span>loaded<span class="w"> </span>at<span class="w"> </span>this<span class="w"> </span>time.<span class="w">
</span><span class="gp">(gdb) info proc mappings</span><span class="w">
</span>Mapped<span class="w"> </span>address<span class="w"> </span>spaces:<span class="w">

          </span>Start<span class="w"> </span>Addr<span class="w">           </span>End<span class="w"> </span>Addr<span class="w">       </span>Size<span class="w">     </span>Offset<span class="w"> </span>objfile<span class="w">
      </span><span class="mh">0x5585a6034000</span><span class="w">     </span><span class="mh">0x5585a604b000</span><span class="w">    </span><span class="mh">0x17000</span><span class="w">        </span><span class="mh">0x0</span><span class="w"> </span>/some/bin<span class="w">
      </span><span class="mh">0x5585a604b000</span><span class="w">     </span><span class="mh">0x5585a64ef000</span><span class="w">   </span><span class="mh">0x4a4000</span><span class="w">    </span><span class="mh">0x17000</span><span class="w"> </span>/some/bin<span class="w">
      </span><span class="mh">0x5585a64ef000</span><span class="w">     </span><span class="mh">0x5585a6582000</span><span class="w">    </span><span class="mh">0x93000</span><span class="w">   </span><span class="mh">0x4bb000</span><span class="w"> </span>/some/bin<span class="w">
      </span><span class="mh">0x7fba3ad28000</span><span class="w">     </span><span class="mh">0x7fba3c000000</span><span class="w">  </span><span class="mh">0x12d8000</span><span class="w">        </span><span class="mh">0x0</span><span class="w"> </span>/dev/shm/...<span class="w">
      </span><span class="mh">0x7fba40d29000</span><span class="w">     </span><span class="mh">0x7fba40f41000</span><span class="w">   </span><span class="mh">0x218000</span><span class="w">        </span><span class="mh">0x0</span><span class="w"> </span>/dev/shm/...<span class="w">
</span></code></pre></div></div> <p>Alright, getting somewhere. I have no idea why <code class="language-plaintext highlighter-rouge">info shared</code> failed but <code class="language-plaintext highlighter-rouge">info proc mappings</code> did not. We want to find a mapping around the address <code class="language-plaintext highlighter-rouge">0x00007fbaa4653c30</code>.</p> <p>Found something.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mh">0x7fbaa4647000</span><span class="w">     </span><span class="mh">0x7fbaa4659000</span><span class="w">    </span><span class="mh">0x12000</span><span class="w">     </span><span class="mh">0x3000</span><span class="w"> </span>/usr/lib/x86_64-linux-gnu/libgcc_s.so.1<span class="w">
</span></code></pre></div></div> <p>The difference between the base address and our <code class="language-plaintext highlighter-rouge">$pc</code> is <code class="language-plaintext highlighter-rouge">0xcc30</code>. Add the offset <code class="language-plaintext highlighter-rouge">0x3000</code> to get <code class="language-plaintext highlighter-rouge">0xfc30</code>.</p> <div class="language-session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$ addr2line -e /usr/lib/x86_64-linux-gnu/libgcc_s.so.1 0xfc30</span><span class="w">
</span>??;0<span class="w">
</span></code></pre></div></div> <p>Okay well thx.</p> <div class="language-session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$ objdump -d -S /usr/lib/x86_64-linux-gnu/libgcc_s.so.1</span><span class="w">
</span>...<span class="w">
</span>fc30:<span class="w">       </span>80<span class="w"> </span>38<span class="w"> </span>48<span class="w">                </span>cmpb<span class="w">   </span>$0x48,(%rax)<span class="w">
    </span>fc33:<span class="w">       </span>0f<span class="w"> </span>85<span class="w"> </span>57<span class="w"> </span>ff<span class="w"> </span>ff<span class="w"> </span>ff<span class="w">       </span>jne<span class="w">    </span>fb90<span class="w"> </span>&lt;_Unwind_GetTextRelBase@@GCC_3.0+0xe40&gt;<span class="w">
    </span>fc39:<span class="w">       </span>48<span class="w"> </span>ba<span class="w"> </span>c7<span class="w"> </span>c0<span class="w"> </span>0f<span class="w"> </span>00<span class="w"> </span>00<span class="w">    </span>movabs<span class="w"> </span>$0x50f0000000fc0c7,%rdx<span class="w">
    </span>...<span class="w">
</span></code></pre></div></div> <p>Okay this wasn’t super useful. This is just some GCC unwinding utility function after a segfault. At this point, I just decide to examine the entire stack.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) x/128xg 0x7fff678eba00</span><span class="w">
</span>...<span class="w">
</span><span class="mh">0x7fff678eba00</span>:<span class="w"> </span><span class="mh">0x00007fba82086040</span><span class="w">      </span><span class="mh">0x00007fbaa465000b</span><span class="w">
</span><span class="mh">0x7fff678eba10</span>:<span class="w"> </span><span class="mh">0x000000000000002e</span><span class="w">      </span><span class="mh">0x0000000000000000</span><span class="w">
</span><span class="mh">0x7fff678eba20</span>:<span class="w"> </span><span class="mh">0x0000000000000000</span><span class="w">      </span><span class="mh">0x0000000000000000</span><span class="w">
</span><span class="mh">0x7fff678eba30</span>:<span class="w"> </span><span class="mh">0x00007fff678eced8</span><span class="w">      </span><span class="mh">0xb741446eb7f0e800</span><span class="w">
</span><span class="mh">0x7fff678eba40</span>:<span class="w"> </span><span class="mh">0x00007fff678eceb0</span><span class="w">      </span><span class="mh">0x00007fff678ebb50</span><span class="w">
</span><span class="mh">0x7fff678eba50</span>:<span class="w"> </span><span class="mh">0x00007fff678ebbf8</span><span class="w">      </span><span class="mh">0x00007fff678ebb50</span><span class="w">
</span><span class="mh">0x7fff678eba60</span>:<span class="w"> </span><span class="mh">0x00007fff678ebe00</span><span class="w">      </span><span class="mh">0x323338342034342d</span><span class="w">
</span>...<span class="w">
</span></code></pre></div></div> <p>Some patterns start to emerge. All values starting with <code class="language-plaintext highlighter-rouge">0x7fff</code> are pointers to things on the stack. Things in the range of <code class="language-plaintext highlighter-rouge">0x7fbaa..</code> are probably related to instructions. We can also see the junk value <code class="language-plaintext highlighter-rouge">0x3233</code> that was implicated in the segfault.</p> <h2 id="two-hours-later-">Two hours later …</h2> <p>My approach was to examine the stack visually, find pointers with prefixes that I knew to map to code I wore, and try and dereference them to get an idea of where my program was when it crashed.</p> <p>This is doable, but it is not as straightforward as you might think. The <em>why</em> requires going into how ELF binaries/shared libraries are loaded in the memory.</p> <ol> <li>There is a <code class="language-plaintext highlighter-rouge">/proc/&lt;pid&gt;/map</code> corresponding to <code class="language-plaintext highlighter-rouge">info proc mappings</code> that we saw earlier.</li> <li>Each ELF file is divided into segments, which are further divided into sections. Mapping happens at the granularity of a segment.</li> <li>The mapped segment will have a different offset than the on-disk segment. This may have something to do with alignment and/or ASLR requirements. But the segment sizes are also different for me, between what is reported by gdb, and what is shown by <code class="language-plaintext highlighter-rouge">readelf/objdump</code>.</li> </ol> <p>As a result, I was unable to map symbol addresses from the core dump to symbols in libraries effectively. There is theoretically no reason why gdb should not be able to do this automatically, and it does, for more benign cases. But it does not seem to load the shared libraries for me for this particular crash.</p> <h2 id="wait-">Wait …</h2> <p>Okay, I ran gdb with this specific sequence, and suddenly it chose to load shared libraries.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$<span class="w"> </span>gdb<span class="w">
</span><span class="gp">(gdb) set auto-solib-add off # do not auto-load solibs</span><span class="w">
</span><span class="gp">(gdb) set substitute-path /dev/shm /dev/null # something for shm maps</span><span class="w">
</span><span class="gp">(gdb) set solib-search-path /path/to/lib</span><span class="w">
</span><span class="gp">(gdb) file /path/to/my/binary</span><span class="w">
</span><span class="gp">(gdb) target core /path/to/core-file</span><span class="w">
</span><span class="gp">(gdb) info sharedlibrary</span><span class="w">
</span><span class="gp">(gdb) info sharedlibrary</span><span class="w">
</span>From<span class="w">                </span>To<span class="w">                  </span>Syms<span class="w"> </span>Read<span class="w">   </span>Shared<span class="w"> </span>Object<span class="w"> </span>Library<span class="w">
</span><span class="mh">0x00007fbaa4e98350</span><span class="w">  </span><span class="mh">0x00007fbaa4eaccd1</span><span class="w">  </span>No<span class="w">          </span>/lib/libx.so<span class="w"> 
</span><span class="mh">0x00007fbaa4e21a00</span><span class="w">  </span><span class="mh">0x00007fbaa4e72bc9</span><span class="w">  </span>No<span class="w">          </span>/lib/liby.so<span class="w">
</span>...<span class="w">
</span><span class="gp">(gdb) sharedlibrary /path/to/libmycode.so</span><span class="w">
</span>Reading<span class="w"> </span>symbols<span class="w"> </span>from<span class="w"> </span>...<span class="w">
</span></code></pre></div></div> <p>I have no idea which of the above did the trick. Consider it a magic sequence of commands for now.</p> <p>The game plan now is to go through the stack with <code class="language-plaintext highlighter-rouge">x/64xg $pc</code> and beyond to look for familiar addresses and try to resolve them via the symbol table. I tried a bunch of random symbols, and finally hit jackpot.</p> <div class="language-gdb highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(gdb) info symbol 0x00005585a6470c80</span><span class="w">
</span>Serialize[...]<span class="w"> </span>in<span class="w"> </span>section<span class="w"> </span>.text<span class="w"> </span>of<span class="w"> </span>/my/binary<span class="w">
</span></code></pre></div></div> <p>It was a buffer overflow in a serialization routine.</p> <h2 id="conclusions">Conclusions</h2> <p>The battle between you and a coy-acting core dump is a battle of wills. Do not blink.</p>]]></content><author><name></name></author><category term="systems"/><category term="gdb"/><summary type="html"><![CDATA[On the applications of fuzzy human pattern matching to extract secrets from a corrupted core dump in the age of trillion parameter AI]]></summary></entry><entry><title type="html">Using Perf Probes to Intercept Variables</title><link href="https://ankushja.in/blog/2024/perf-inspect-vars/" rel="alternate" type="text/html" title="Using Perf Probes to Intercept Variables"/><published>2024-05-29T22:12:07+00:00</published><updated>2024-05-29T22:12:07+00:00</updated><id>https://ankushja.in/blog/2024/perf-inspect-vars</id><content type="html" xml:base="https://ankushja.in/blog/2024/perf-inspect-vars/"><![CDATA[<p><a href="">Part 1</a> and <a href="">Part 2</a> of this series at the respective links.</p> <p>This is a case study in using perf probes to monitor the values of some variable from a process, without having to modify its code.</p> <p>We are interested in monitoring the number of objects allocated by a library called <code class="language-plaintext highlighter-rouge">psm</code>. We know that they are available in a function called <code class="language-plaintext highlighter-rouge">psmmpool_get</code>. The object available there is called <code class="language-plaintext highlighter-rouge">mp</code> and it has members <code class="language-plaintext highlighter-rouge">mp_num_obj</code> and <code class="language-plaintext highlighter-rouge">mp_num_obj_inuse</code> that we want to monitor.</p> <p>First, set up your permissions.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">sudo </span>addgroup tracing
<span class="nb">sudo </span>usermod <span class="nt">-aG</span> ankush tracing
newgrp tracing <span class="c"># "activate" group without having to log out</span>
<span class="nb">sudo </span>mount <span class="nt">-o</span> remount,mode<span class="o">=</span>755 /sys/kernel/debug
<span class="nb">sudo </span>mount <span class="nt">-o</span> remount,mode<span class="o">=</span>755 /sys/kernel/debug/tracing
<span class="nb">echo </span>0 | <span class="nb">sudo tee</span> /proc/sys/kernel/kptr_restrict
<span class="nb">echo</span> <span class="nt">-1</span> | <span class="nb">sudo tee</span> /proc/sys/kernel/perf_event_paranoid
<span class="nb">sudo chown </span>root:tracing /sys/kernel/debug/tracing/uprobe_events
<span class="nb">sudo chmod </span>g+rw /sys/kernel/debug/tracing/uprobe_events
</code></pre></div></div> <p>Next, we execute these commands to explore the available perf points and tap into them</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">PSM</span><span class="o">=</span>/path/to/libpsm_infinipath.so

perf probe <span class="nt">-x</span> <span class="nv">$PSM</span> <span class="nt">--funcs</span> <span class="c"># lists probe-able functions</span>
perf probe <span class="nt">-x</span> <span class="nv">$PSM</span> <span class="nt">--funcs</span> | <span class="nb">grep </span>psmi_mpool_get <span class="c"># this is present</span>
perf probe <span class="nt">-x</span> <span class="nv">$PSM</span> <span class="nt">-L</span> psmi_mpool_get <span class="c"># view the source for this function</span>
perf probe <span class="nt">-x</span> <span class="nv">$PSM</span> <span class="nt">--vars</span> psmi_mpool_get <span class="c"># view available vars here.</span>

<span class="c"># mp is available in psmi_mpool_get</span>

<span class="c"># need mp-&gt;mp_num_obj and mp-&gt;mp_num_obj_inuse</span>
perf probe <span class="nt">-x</span> <span class="nv">$PSM</span> <span class="s1">'psm:nobj=psmi_mpool_get mp-&gt;mp_num_obj'</span>
perf probe <span class="nt">-x</span> <span class="nv">$PSM</span> <span class="s1">'psm:nused=psmi_mpool_get mp-&gt;mp_num_obj_inuse'</span>
</code></pre></div></div> <p>List active probes to confirm that they got added</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ perf probe -l
  psm:nobj             (on psmi_mpool_get@src/psm/psm_mpool.c in ...&gt;
  psm:nused            (on psmi_mpool_get@src/psm/psm_mpool.c in ...&gt;
</code></pre></div></div> <p>Start recording for all probes.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>perf record <span class="nt">-e</span> psm:nobj <span class="nt">-e</span> psm:nused <span class="nt">-a</span>
<span class="c"># run code from a different tab</span>
^C
perf script <span class="c"># this will show us what was emitted</span>
</code></pre></div></div> <p>Output:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> bin-using-psm 381026 [002] 417634.233519: psm:nused: (7f9980230350) mp_num_obj_inuse=0x0
 bin-using-psm 381027 [003] 417634.233519: psm:nused: (7fcc080f5350) mp_num_obj_inuse=0x0
 bin-using-psm 381028 [004] 417634.233519: psm:nused: (7fc05836e350) mp_num_obj_inuse=0x0
 bin-using-psm 381027 [003] 417634.233522:  psm:nobj: (7fcc080f5350) mp_num_obj=0x400
 bin-using-psm 381028 [004] 417634.233522:  psm:nobj: (7fc05836e350) mp_num_obj=0x400
 bin-using-psm 381026 [002] 417634.233522:  psm:nobj: (7f9980230350) mp_num_obj=0x400
 bin-using-psm 381029 [005] 417634.233523: psm:nused: (7fa818f52350) mp_num_obj_inuse=0x0
 bin-using-psm 381029 [005] 417634.233525:  psm:nobj: (7fa818f52350) mp_num_obj=0x400
 bin-using-psm 381030 [006] 417634.233525: psm:nused: (7f69a6c35350) mp_num_obj_inuse=0x0
 bin-using-psm 381030 [006] 417634.233527:  psm:nobj: (7f69a6c35350) mp_num_obj=0x400
</code></pre></div></div> <p>Bingo — we have the data. Other things:</p> <ol> <li>We can point <code class="language-plaintext highlighter-rouge">perf record</code> to a particular PID to record its values.</li> <li>We can process the data via say python using <code class="language-plaintext highlighter-rouge">perf script -g python</code></li> </ol> <p>Something like this will show the number of occurrences in real time, but AFAIK, can not show data embedded in the probe.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>perf <span class="nb">stat</span> <span class="nt">-a</span> <span class="nt">-e</span> psm:nobj <span class="nt">-I</span> 1000
</code></pre></div></div> <h3 id="references">References</h3>]]></content><author><name></name></author><category term="perf"/><category term="perf"/><summary type="html"><![CDATA[Intercept process variables without having to modify it]]></summary></entry><entry><title type="html">On Intelligence: Assessment and Directions</title><link href="https://ankushja.in/blog/2024/llm-intelligence/" rel="alternate" type="text/html" title="On Intelligence: Assessment and Directions"/><published>2024-05-15T05:53:05+00:00</published><updated>2024-05-15T05:53:05+00:00</updated><id>https://ankushja.in/blog/2024/llm-intelligence</id><content type="html" xml:base="https://ankushja.in/blog/2024/llm-intelligence/"><![CDATA[<p>So the topic for this post is a bit of a departure from my usual mucking in the sewers that modern systems are. I have been fascinated by LLMs, and what they are missing enroute to “AGI”. This is a collection of some of those thoughts that have been brewing over the past few months. I am not particularly familiar with the related work in this area, and this is mostly coming from first principles, with some random inputs from here and there folded in.</p> <p>I have no calibration for how much of this is just me reiterating what is already known and well-understood, or obvious, or deeply flawed.</p> <h2 id="llms-as-currently-designed-can-not-be-reasoning">LLMs, As Currently Designed, Can Not Be Reasoning</h2> <p>This idea emerged in my head in the early days of GPT-3. Its prowess was shocking, and everyone started reassessing everything (<em>autogaslighting</em>). And then we started noticing a million ways to “crack” it, relaxed a little, and things got better with GPT-4/4o.</p> <p>This intuition is simple — LLMs generate text at a constant token rate, and an intelligent agent simply can not do that. For a simple query, an intelligent agent is able to respond instantly, while for a complex query, it needs to go and <em>think</em> and <em>plan</em> a response. There can not be any upper bound to the amount of time this takes.</p> <p>LLMs seem to encode some constant amount of capability. It is perfectly okay for a new (yet not fully optimized architecture that is on the right track) to take more time than necessary for a simple query, but an architecture that can not take an infinite time can not be reasoning.</p> <p>I have come across the term “out-of-distribution” to describe hallucination etc, and I think it offers a good way to think about LLMs — they form a distribution over all that is known, and are able to generate samples from that distribution. For why this does not amount to reasoning, read on and I think you will have a better idea of how this is going.</p> <h2 id="llms-as-a-snapshot-of-intuition">LLMs as a Snapshot of Intuition</h2> <p>I think LLMs are a lot more similar to <em>intuition</em>. Intuition is the mechanism by which we generate instant responses — these can be right, or wrong. I say <em>a snapshot of intuition</em> because human intuition constantly refines itself, and model weights are static.</p> <p>Intuition is a different property from <em>planning</em> and <em>reasoning</em>. I will describe this more in the “human learning” section — I feel that there are circular dependencies here and I can not seem to figure out a great order to put this in.</p> <p>Drawing an equivalence between LLMs and intuition has two interesting corollaries:</p> <ol> <li>It provides an explanation for why we are building massive and expensive models. This is somewhat similar to building an intuition so strong that you make up for an inability to reason.</li> <li>It maps them to a component of the grand architecture of “human cognitive ability”. This would imply that while we (as the human race) have not yet figured out the entire architecture, this is fundamentally similar to a building block.</li> </ol> <p>I do feel that the fundamental approach to synthesizing “capability” by “exposing” a neural network to lots of data is valid and powerful. This is in contrast to coding and program synthesis, where “capability” is hand-crafted line-by-line. This is not to say that the latter approaches are not valid, but that the former allows for capabilities the latter does not (and vice-versa), and seems to mirror aspects of the elusive human intelligence.</p> <h3 id="a-model-of-human-intelligence">A Model of Human Intelligence</h3> <p>I think my point should make a lot more sense if I explain my model of human intelligence.</p> <p>Say a “rational” human being is asked a question (say a physics situation involving some bodies). This is the sequence of steps they take:</p> <ol> <li>They have an initial intuition of how they expect the system to behave.</li> <li>They try to formally solve it by modeling it as a set of equations, solve the equations, and get a result.</li> <li>Let us pretend that they get a result that they believe is “counterintuitive”. They recheck their math and if it holds, accept that “while my intuition suggests otherwise, this must be true.”</li> <li>Over time, their intuition internalizes what the math says, and a year later if they are asked a similar question, their instinct is a lot closer.</li> </ol> <p>Now we can define <em>reasoning</em> and <em>planning</em>.</p> <ul> <li><em>Reasoning</em> is just modeling a situation as a set of logical statements, and them symbolically validating those statements.</li> <li><em>Planning</em> is decomposing a problem into a series of subproblems, possibly recursively, and solving the smaller subproblems, and composing all the leaf nodes into a solution for the bigger problem. <ul> <li>The “plan” for an “agent” can include “actions”. Over the course of trying to solve a problem, they may ask other agents for assistance, build machines, or take any other action within its scope.</li> </ul> </li> </ul> <p>“Agents” also “meta-reason” and “meta-intuit”. They think about whether their plan is logically valid or not. They have different preference profiles over the set of candidate actions. (Some are more likely to approach other agents, others may prefer choosing goals that avoid interactions etc.) These heuristics lead to emergent traits such as personality, extroversion, neuroticism etc.</p> <h2 id="a-lesson-from-flight">A Lesson from Flight</h2> <p>Now how does all this apply to how to build such capabilities? That is the quadrillion dollar question.</p> <p>How humans cracked flight is, in my opinion, an instructive parallel. That birds could fly established that flight is possible. However, the mechanics we use to actually fly are very different — our aircraft do not flap their wings. We probably still can not build a meaningful wing-flapping aircraft. That in no way limits our ability to leverage aviation and structure our entire economies around that capability being commonplace.</p> <p>The same holds for LLMs. They need <em>reasoning</em> and <em>planning</em>, but the way they achieve these capabilities may be very different from the way we evolved. Life evolved as a self-sustaining Minimal Viable Product that could mutate to gain capabilities. We may be able to stitch together a “self-sustaining cognitive loop” directly from larger pieces. Or we may find that the easier way to do it is to build simpler agents and let them self-mutate to acquire capability.</p> <p>I think a variety of architectures are possible — autonomous and not. It is not necessary that they are conscious, “alive”, have free will, have feelings, etc.</p> <h2 id="a-lesson-from-organic-chemistry">A Lesson from Organic Chemistry</h2> <p>Before the 18th century, we believed that certain molecules, associated with living beings, had an inherent life force, and therefore could not be synthesized artificially. From Wikipedia:</p> <blockquote> <p>In 1828 <a href="https://en.wikipedia.org/wiki/Friedrich_W%C3%B6hler" title="Friedrich Wöhler">Friedrich Wöhler</a> produced the <em>organic</em> chemical <a href="https://en.wikipedia.org/wiki/Urea" title="Urea">urea</a> (carbamide), a constituent of <a href="https://en.wikipedia.org/wiki/Urine" title="Urine">urine</a>, from <em>inorganic</em> starting materials (the salts <a href="https://en.wikipedia.org/wiki/Potassium_cyanate" title="Potassium cyanate">potassium cyanate</a> and <a href="https://en.wikipedia.org/wiki/Ammonium_sulfate" title="Ammonium sulfate">ammonium sulfate</a>), in what is now called the <a href="https://en.wikipedia.org/wiki/W%C3%B6hler_synthesis" title="Wöhler synthesis">Wöhler synthesis</a>.</p> </blockquote> <p>It was then that we realized that organic molecules have nothing inherently different from others. They could be synthesized, hacked, and novel ones could be created to trick our bodies into working a certain way.</p> <p>I think that to the extent we think about intelligence as something inherent to humans, we will shortly be proven wrong. I also think that it will be less of a breakthrough moment than a series of continual improvements of the kind we are currently in the midst of — deeply shaping the way we work and organize human productivity along the way.</p>]]></content><author><name></name></author><category term="ml"/><category term="ml"/><category term="llm"/><category term="aligners"/><summary type="html"><![CDATA[How far have LLMs gotten us? What remains? What will "the rest" take?]]></summary></entry></feed>